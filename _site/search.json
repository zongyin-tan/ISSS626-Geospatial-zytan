[
  {
    "objectID": "Take-home_Ex/Take_home_Ex1/Take-home_Ex1.html",
    "href": "Take-home_Ex/Take_home_Ex1/Take-home_Ex1.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "The locations of businesses and firms are central to urban development, influencing economic growth, job creation, and the availability of resources and services for residents and other businesses. Strategic locations provide competitive advantages, access to talent and infrastructure, and impact brand image and market positioning, while also shaping the city’s overall character and functionality by fostering specialized districts and facilitating efficient supply chains and employee commutes.\nStudying the spatio-temporal patterns of businesses and firms is crucial for urban development because it reveals how economic activity and urban forms evolve, enabling better urban planning, promoting sustainability, identifying urban inefficiencies, and enhancing quality of life. By understanding where and when businesses locate and operate, urban planners can design cities more effectively, anticipate growth, ensure resource efficiency, and tailor infrastructure to support economic vitality and community well-being."
  },
  {
    "objectID": "Take-home_Ex/Take_home_Ex1/Take-home_Ex1.html#importing-the-data",
    "href": "Take-home_Ex/Take_home_Ex1/Take-home_Ex1.html#importing-the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Importing the Data",
    "text": "Importing the Data\nThe following code chunk is used to import all the ACRA .csv files from the folder and combine them into a single dataset. This allows us to manage and analyze the data more efficiently within R. At the end of the code we will use glimpse() to have an overview of the data fields and their data type to confirm if they are in their correct format.\n\npath &lt;- \"data\"\n\nfiles &lt;- list.files(path = path, \n                    pattern = \"ACRA Information on Corporate Entities.*\\\\.csv\", \n                    full.names = TRUE)\n\nacra_data &lt;- files %&gt;% \n  map_dfr(~ read_csv(.x, show_col_types = FALSE))\n\nglimpse(acra_data)\n\nRows: 2,026,935\nColumns: 53\n$ uen                               &lt;chr&gt; \"00022100K\", \"00031800X\", \"00043100A…\n$ issuance_agency_id                &lt;chr&gt; \"ACRA\", \"ACRA\", \"ACRA\", \"ACRA\", \"ACR…\n$ entity_name                       &lt;chr&gt; \"A Y ABDUL RAHIMAN\", \"A M ABDULLAH S…\n$ entity_type_description           &lt;chr&gt; \"Sole Proprietorship/ Partnership\", …\n$ business_constitution_description &lt;chr&gt; \"Partnership\", \"Partnership\", \"Partn…\n$ company_type_description          &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ paf_constitution_description      &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ entity_status_description         &lt;chr&gt; \"Terminated\", \"Terminated\", \"Termina…\n$ registration_incorporation_date   &lt;date&gt; 1974-10-09, 1974-10-12, 1974-09-20,…\n$ uen_issue_date                    &lt;date&gt; 1974-10-09, 1974-10-12, 1974-09-20,…\n$ address_type                      &lt;chr&gt; \"LOCAL\", \"LOCAL\", \"LOCAL\", \"LOCAL\", …\n$ block                             &lt;chr&gt; \"51\", \"93\", \"178\", \"21\", \"30\", \"38A\"…\n$ street_name                       &lt;chr&gt; \"EAST COAST ROAD\", \"MARKET STREET\", …\n$ level_no                          &lt;chr&gt; \"na\", \"10\", \"na\", \"na\", \"na\", \"na\", …\n$ unit_no                           &lt;chr&gt; \"na\", \"01\", \"na\", \"na\", \"na\", \"na\", …\n$ building_name                     &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ postal_code                       &lt;chr&gt; \"428770\", \"0104\", \"0718\", \"0923\", \"4…\n$ other_address_line1               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ other_address_line2               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ account_due_date                  &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ annual_return_date                &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ primary_ssic_code                 &lt;dbl&gt; 47722, 46301, 68104, 56111, 47102, 6…\n$ primary_ssic_description          &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ primary_user_described_activity   &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ secondary_ssic_code               &lt;chr&gt; \"na\", \"32909\", \"na\", \"56122\", \"na\", …\n$ secondary_ssic_description        &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ secondary_user_described_activity &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ no_of_officers                    &lt;dbl&gt; 7, 6, 3, 1, 5, 2, 2, 1, 4, 2, 2, 1, …\n$ former_entity_name1               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name2               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name3               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name4               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name5               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name6               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name7               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name8               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name9               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name10              &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name11              &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name12              &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name13              &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name14              &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ former_entity_name15              &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ uen_of_audit_firm1                &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ name_of_audit_firm1               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ uen_of_audit_firm2                &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ name_of_audit_firm2               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ uen_of_audit_firm3                &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ name_of_audit_firm3               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ uen_of_audit_firm4                &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ name_of_audit_firm4               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ uen_of_audit_firm5                &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ name_of_audit_firm5               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …"
  },
  {
    "objectID": "Take-home_Ex/Take_home_Ex1/Take-home_Ex1.html#data-preparation",
    "href": "Take-home_Ex/Take_home_Ex1/Take-home_Ex1.html#data-preparation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nDropping irrelevant data fields\nTo streamline the dataset for analysis, we will select only the relevant fields identified through the glimpse() function shown above. This step ensures that we focus on the essential variables needed for our study, resulting in a cleaner and more manageable dataset.\nFor geocoding, location information can be derived either from the combination of block and street_name fields, or directly from the postal_code. To ensure data quality, we use the following code chunk to check for any missing values in these fields.\n\nacra_data %&gt;%\n  filter(is.na(block) | block == \"\" |\n         is.na(street_name) | street_name == \"\" |\n         is.na(postal_code) | postal_code == \"\") %&gt;%\n  select(uen, entity_name, block, street_name, postal_code) %&gt;%\n  glimpse()\n\nRows: 2\nColumns: 5\n$ uen         &lt;chr&gt; \"53323605C\", \"53292643M\"\n$ entity_name &lt;chr&gt; \"HONSHIN GOLF ACADEMY\", \"ROSHALIN\"\n$ block       &lt;chr&gt; NA, NA\n$ street_name &lt;chr&gt; \"MANDAI ROAD\", \"QUEENSWAY\"\n$ postal_code &lt;chr&gt; \"779384\", \"149051\"\n\n\nSince there are missing block numbers within the dataset, we will proceed to use the postal codes for geocoding. The following code chunk will be used to select the data fields we want for our dataset.\n\nacra_selected &lt;- acra_data %&gt;%\n  select(\n    uen,\n    entity_name,\n    entity_type_description,\n    entity_status_description,\n    registration_incorporation_date,\n    primary_ssic_code,\n    address_type,\n    postal_code\n  )\n\nglimpse(acra_selected)\n\nRows: 2,026,935\nColumns: 8\n$ uen                             &lt;chr&gt; \"00022100K\", \"00031800X\", \"00043100A\",…\n$ entity_name                     &lt;chr&gt; \"A Y ABDUL RAHIMAN\", \"A M ABDULLAH SAH…\n$ entity_type_description         &lt;chr&gt; \"Sole Proprietorship/ Partnership\", \"S…\n$ entity_status_description       &lt;chr&gt; \"Terminated\", \"Terminated\", \"Terminate…\n$ registration_incorporation_date &lt;date&gt; 1974-10-09, 1974-10-12, 1974-09-20, 1…\n$ primary_ssic_code               &lt;dbl&gt; 47722, 46301, 68104, 56111, 47102, 681…\n$ address_type                    &lt;chr&gt; \"LOCAL\", \"LOCAL\", \"LOCAL\", \"LOCAL\", \"L…\n$ postal_code                     &lt;chr&gt; \"428770\", \"0104\", \"0718\", \"0923\", \"439…\n\n\n\n\nDropping Irrelevant Records\nFor this exercise, we will be looking at the following trades using the SICC classification:\n\n47- Retail Trade\n56 - Food and Beverage Service Activities\n86 - Health Services\n\nThe following code chunk will be used to filter and leave the above mentioned types of businesses within our dataset.\n\nacra_ssic &lt;- acra_selected %&gt;%\n  filter(str_starts(primary_ssic_code, \"47\") |\n         str_starts(primary_ssic_code, \"56\") |\n         str_starts(primary_ssic_code, \"86\"))\n\nglimpse(acra_ssic)\n\nRows: 337,860\nColumns: 8\n$ uen                             &lt;chr&gt; \"00022100K\", \"00043800J\", \"00063200K\",…\n$ entity_name                     &lt;chr&gt; \"A Y ABDUL RAHIMAN\", \"AI HOU KEE ORIEN…\n$ entity_type_description         &lt;chr&gt; \"Sole Proprietorship/ Partnership\", \"S…\n$ entity_status_description       &lt;chr&gt; \"Terminated\", \"Cancelled\", \"Cancelled\"…\n$ registration_incorporation_date &lt;date&gt; 1974-10-09, 1974-09-25, 1974-10-21, 1…\n$ primary_ssic_code               &lt;dbl&gt; 47722, 56111, 47102, 47230, 56111, 471…\n$ address_type                    &lt;chr&gt; \"LOCAL\", \"LOCAL\", \"LOCAL\", \"LOCAL\", \"L…\n$ postal_code                     &lt;chr&gt; \"428770\", \"0923\", \"439561\", \"0718\", \"0…\n\n\nWe want to only have the records of business entities registered between 1st January 2024 to 30th June 2026. Before we filter, it is good practice to check the data type. The following code chunk will be used to check the data type.\n\nclass(acra_ssic$registration_incorporation_date)\n\n[1] \"Date\"\n\n\nAfter confirming the data type, we can proceed to filter the records.\n\nacra_filtered &lt;- acra_ssic %&gt;%\n  filter(registration_incorporation_date &gt;= as.Date(\"2024-01-01\") &\n         registration_incorporation_date &lt;= as.Date(\"2025-06-30\"))\n\nglimpse(acra_filtered)\n\nRows: 16,944\nColumns: 8\n$ uen                             &lt;chr&gt; \"202400088M\", \"202400369C\", \"202400511…\n$ entity_name                     &lt;chr&gt; \"AEMN GROUP PTE. LTD.\", \"AVENUE OF BRA…\n$ entity_type_description         &lt;chr&gt; \"Local Company\", \"Local Company\", \"Loc…\n$ entity_status_description       &lt;chr&gt; \"Live Company\", \"Live Company\", \"Live …\n$ registration_incorporation_date &lt;date&gt; 2024-03-13, 2024-01-02, 2024-01-03, 2…\n$ primary_ssic_code               &lt;dbl&gt; 47220, 56122, 86201, 56111, 47219, 561…\n$ address_type                    &lt;chr&gt; \"LOCAL\", \"LOCAL\", \"LOCAL\", \"LOCAL\", \"L…\n$ postal_code                     &lt;chr&gt; \"49909\", \"349585\", \"408564\", \"208511\",…"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03a.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03a.html",
    "title": "In-class Exercise 3: Interactive K-function",
    "section": "",
    "text": "pacman::p_load(sf, terra, spatstat, \n               tmap, rvest, tidyverse,\n               ggthemes, plotly)\nchildcare_sf &lt;- read_rds(\"data/rds/childcare_sf.rds\")\nchildcare_ppp &lt;- as.ppp(childcare_sf) %&gt;%\n  rjitter(retry = TRUE,\n          nsim = 1,\n          drop = TRUE)\npg &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03a.html#building-an-interative-plot-with-ggplotly",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03a.html#building-an-interative-plot-with-ggplotly",
    "title": "In-class Exercise 3: Interactive K-function",
    "section": "Building an interative plot with ggplotly",
    "text": "Building an interative plot with ggplotly\nThe previous code chunks uses plot() to visualise the envelopes of the second-order summary statistics (such as L-function). The output is a static plot, therefore it can be difficult to make accurate guesstimates of the statistics and the corresponding distance, r.\nThe below code chunk converts the output (which is in a list form) into a dataframe, which can be used to generate a similar plot using appropriate aesthetic mappings from ggplot package. Finally, ggplotly() is used to convert the ggplot into an interactive plotly visualisation.\nThe codes were referenced from a R-blogger article. Further modifications were made to enhance the user experience by customizing the tooltips for greater clarity and intuition.\n\ntitle &lt;- \"Pairwise Distance: L function\"\n\nLcsr_df &lt;- as.data.frame(L_tm.csr)\n\ncolour=c(\"#0D657D\",\"#ee770d\",\"#D3D3D3\")\ncsr_plot &lt;- ggplot(Lcsr_df, aes(r, obs-r))+\n  # plot observed value\n  geom_line(colour=c(\"#4d4d4d\"))+\n  geom_line(aes(r,theo-r), colour=\"red\", linetype = \"dashed\")+\n  # plot simulation envelopes\n  geom_ribbon(aes(ymin=lo-r,ymax=hi-r),alpha=0.1, colour=c(\"#91bfdb\")) +\n  xlab(\"Distance r (m)\") +\n  ylab(\"L(r)-r\") +\n  geom_rug(data=Lcsr_df[Lcsr_df$obs &gt; Lcsr_df$hi,], sides=\"b\", colour=colour[1])  +\n  geom_rug(data=Lcsr_df[Lcsr_df$obs &lt; Lcsr_df$lo,], sides=\"b\", colour=colour[2]) +\n  geom_rug(data=Lcsr_df[Lcsr_df$obs &gt;= Lcsr_df$lo & Lcsr_df$obs &lt;= Lcsr_df$hi,], sides=\"b\", color=colour[3]) +\n  theme_tufte()+\n  ggtitle(title)\n\ntext1&lt;-\"Significant clustering\"\ntext2&lt;-\"Significant segregation\"\ntext3&lt;-\"Not significant clustering/segregation\"\n\n# the below conditional statement is required to ensure that the labels (text1/2/3) are assigned to the correct traces\nif (nrow(Lcsr_df[Lcsr_df$obs &gt; Lcsr_df$hi,])==0){ \n  if (nrow(Lcsr_df[Lcsr_df$obs &lt; Lcsr_df$lo,])==0){ \n    ggplotly(csr_plot, dynamicTicks=T) %&gt;%\n      style(text = text3, traces = 4) %&gt;%\n      rangeslider() \n  }else if (nrow(Lcsr_df[Lcsr_df$obs &gt;= Lcsr_df$lo & Lcsr_df$obs &lt;= Lcsr_df$hi,])==0){ \n    ggplotly(csr_plot, dynamicTicks=T) %&gt;%\n      style(text = text2, traces = 4) %&gt;%\n      rangeslider() \n  }else {\n    ggplotly(csr_plot, dynamicTicks=T) %&gt;%\n      style(text = text2, traces = 4) %&gt;%\n      style(text = text3, traces = 5) %&gt;%\n      rangeslider() \n  }\n} else if (nrow(Lcsr_df[Lcsr_df$obs &lt; Lcsr_df$lo,])==0){\n  if (nrow(Lcsr_df[Lcsr_df$obs &gt;= Lcsr_df$lo & Lcsr_df$obs &lt;= Lcsr_df$hi,])==0){\n    ggplotly(csr_plot, dynamicTicks=T) %&gt;%\n      style(text = text1, traces = 4) %&gt;%\n      rangeslider() \n  } else{\n    ggplotly(csr_plot, dynamicTicks=T) %&gt;%\n      style(text = text1, traces = 4) %&gt;%\n      style(text = text3, traces = 5) %&gt;%\n      rangeslider()\n  }\n} else{\n  ggplotly(csr_plot, dynamicTicks=T) %&gt;%\n    style(text = text1, traces = 4) %&gt;%\n    style(text = text2, traces = 5) %&gt;%\n    style(text = text3, traces = 6) %&gt;%\n    rangeslider()\n  }\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe main features of the above visualisation:\n\nThe observed and theoretical values of L(r)-r (including the upper and lower curves of the simulated envelope) can be found in the tooltip upon hovering the cursor over the geometry layers.\nThe range slider below the plot enables users to pan and zoom in to a specific range of distance.\nThe colored bands at the bottom of the line graph gives a clearer indication of significant or insignificant spatial segregation/ clustering at distance r. Dark green bands indicate significant clustering, orange indicate significant segregation, while grey indicates insignificant clustering/segregation.\nTooltips were added to provide color legend information."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/In-class_Ex03/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "ISSS626-Geospatial-zytan",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],MEMBER[“World Geodetic System 1984 (G2296)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called a space-time point process) is a random set of points where each point represents both the location and the time of an event. Examples include disease cases, species sightings or births, and natural hazards such as fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nWith the rapid growth of data that is tagged by both location and time, analyzing spatio-temporal point patterns has become increasingly important across many fields. In the past decade, several methods for such analysis have been developed and implemented in R. This chapter demonstrates how different R packages can be combined to carry out spatio-temporal point pattern analysis in a practical and intuitive way using real-world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1 January to 31 December 2023."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-study-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-study-area",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Importing study area",
    "text": "Importing study area\nThe code chunk below will be used to import the study area Kepulauan Bangka Belitung into the R environment.\n\nkbb &lt;- st_read(dsn=\"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") \n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex03\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 297 features and 26 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nkbb_sf &lt;- st_read(dsn=\"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex03\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 297 features and 26 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\nclass(kbb_owin)\n\n[1] \"owin\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overall-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overall-plot",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Overall plot",
    "text": "Overall plot\nBelow is the code chunk used to plot the fire points onto the map.\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-geographic-distribution-of-forest-fires-by-month",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-geographic-distribution-of-forest-fires-by-month",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Visualising geographic distribution of forest fires by month",
    "text": "Visualising geographic distribution of forest fires by month\nBelow is the fire distribution points for each month of the year which is split using the Month_fac column. The following code chunk will be used for the visualisation.\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\ntm_facets(by=\"Month_fac\", \n            free.coords=FALSE, \n            drop.units = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#extracting-forest-fires-by-month",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#extracting-forest-fires-by-month",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Extracting forest fires by month",
    "text": "Extracting forest fires by month\nppp files only require the geometry (spatial locations) and/or marks (the attributes linked to each point) fields. Hence the following code chunk will be used to drop all non required fields.\n\nfire_month &lt;- fire_sf %&gt;% \n  select(Month_num)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-ppp",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-ppp",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Creating ppp",
    "text": "Creating ppp\nAfter cleaning is completed, we will then proceed to create the ppp object based on the months using the following code chunk.\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\nWe can use summary() to check our newly created ppp object.\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\nWe will need to check if there is any duplicated points as well using the following code chunk.\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#including-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#including-owin-object",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Including Owin object",
    "text": "Including Owin object\nWe will now merge the layers fire_month_ppp which contains the fire points and kbb_owin which is the map layer together into a new object fire_month_owin.\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.42469e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 47493 vertices\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533600000 square units\nFraction of frame area: 0.334\n\n\nWe will then proceed to plot the newly created object to check for correctness.\n\nplot(fire_month_owin)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-spatio-temporal-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-spatio-temporal-kde",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Computing Spatio-temporal KDE",
    "text": "Computing Spatio-temporal KDE\nUsing spattemp.density(), we compute the STKDE.\nThe resulting density surface provides insight into when and where fire occurrences were most concentrated, highlighting the patterns of fire activity.\n\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-spatio-temporal-kde-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-spatio-temporal-kde-object",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Plotting the spatio-temporal KDE object",
    "text": "Plotting the spatio-temporal KDE object\nWe will use plot() on the KDE between July 2023 to Decemeber 2023 for visualisation.\n\ntims &lt;- c(7,8,9,10,11,12)\npar(mfcol=c(2,3), mar=c(4,4,4,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at month\",i),\n       cex.main=1.2)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-ppp-object-including-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-ppp-object-including-owin-object",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Creating ppp object + Including Owin object",
    "text": "Creating ppp object + Including Owin object\nThe following code chunk will be used to create the ppp object based on the DayofYear field afterwhich we will create our owin object by merging and layers. Finally it will provide us the summary of our owin file.\n\nfire_yday_ppp &lt;- fire_sf %&gt;% \n  select(DayofYear) %&gt;%\n  as.ppp()\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\nsummary(fire_yday_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.42469e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   213.0   258.0   245.9   287.0   352.0 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 47493 vertices\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533600000 square units\nFraction of frame area: 0.334\n\n\nWe will next use spattemp.density() to compute the STKDE.\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 6.3198 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [3.959516e-27, 2.751287e-12]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-output-spatio-temporal-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-output-spatio-temporal-kde",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Plotting the output spatio-temporal KDE",
    "text": "Plotting the output spatio-temporal KDE\nFinally, we plot our KDE\n\nplot(kde_yday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-spatio-temporal-kde-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-spatio-temporal-kde-1",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Computing spatio-temporal KDE",
    "text": "Computing spatio-temporal KDE\nWith the h and lambda values derived from BOOT.spattemp(), we can use them to compute our STKDE with the following code chunk.\n\nkde_yday &lt;- spattemp.density(fire_yday_owin,\n                             h = 9000,\n                             lambda = 19)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 9000 (spatial)\n  lambda = 19 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [2.001642e-19, 2.445724e-12]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-output-spatio-temporal-kde-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-output-spatio-temporal-kde-1",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Plotting the output spatio-temporal KDE",
    "text": "Plotting the output spatio-temporal KDE\nFinally we can plot with our newly computed KDE.\n\nplot(kde_yday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Unlike First-order spatial point pattern, which looks at how point density varies across space, Second-order spatial point pattern analysis examines the relationships between points themselves. It asks whether points cluster together, spread out evenly or occur randomly.\nThis will help us answer questions like:\n\nAre the childcare centres in Singapore randomly distributed throughout the country?\nIf the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#preparation-of-master-plan-2019-subzone-no-sea-dataset",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#preparation-of-master-plan-2019-subzone-no-sea-dataset",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Preparation of Master Plan 2019 Subzone (No Sea) dataset",
    "text": "Preparation of Master Plan 2019 Subzone (No Sea) dataset\nThe dataset is prepared for the end result of an owin file called sg_owin.\n\n\nShow code\nextract_kml_field &lt;- function(html_text, field_name) {\n  if (is.na(html_text) || html_text == \"\") return(NA_character_)\n  \n  page &lt;- read_html(html_text)\n  rows &lt;- page %&gt;% html_elements(\"tr\")\n  \n  value &lt;- rows %&gt;%\n    keep(~ html_text2(html_element(.x, \"th\")) == field_name) %&gt;%\n    html_element(\"td\") %&gt;%\n    html_text2()\n  \n  if (length(value) == 0) NA_character_ else value\n}\n\nmpsz_sf &lt;- mpsz_sf %&gt;%\n  mutate(\n    REGION_N = map_chr(Description, extract_kml_field, \"REGION_N\"),\n    PLN_AREA_N = map_chr(Description, extract_kml_field, \"PLN_AREA_N\"),\n    SUBZONE_N = map_chr(Description, extract_kml_field, \"SUBZONE_N\"),\n    SUBZONE_C = map_chr(Description, extract_kml_field, \"SUBZONE_C\")\n  ) %&gt;%\n  select(-Name, -Description) %&gt;%\n  relocate(geometry, .after = last_col())\n\nmpsz_cl &lt;- mpsz_sf %&gt;%\n  filter(SUBZONE_N != \"SOUTHERN GROUP\",\n         PLN_AREA_N != \"WESTERN ISLANDS\",\n         PLN_AREA_N != \"NORTH-EASTERN ISLANDS\")\n\nsg_owin &lt;- as.owin(mpsz_cl)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#preparation-of-childcare-centre-dataset",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#preparation-of-childcare-centre-dataset",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Preparation of childcare centre dataset",
    "text": "Preparation of childcare centre dataset\nThe dataset is prepared for the end result of a ppp file. sg_owin file is combined into the data points of childcare_ppp file.\n\n\nShow code\nchildcare_sf &lt;- st_read(\"data/ChildCareServices.kml\") %&gt;% \n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `CHILDCARE' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex02b\\data\\ChildCareServices.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nShow code\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nchildcareSG_ppp = childcare_ppp[sg_owin]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-g-function",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using G-Function",
    "text": "Analysing Spatial Point Process Using G-Function\nThe G-function measures the distances from each point in a dataset to its nearest neighboring point and summarizes these distances across the study area. In simple terms, it shows how close points are to each other and whether they tend to cluster or spread out.\nWe will be using Gest() for the computing of G-function and envelope() for the monte carlo simulation. These 2 functions are of the spatstat package.\n\nChoa Chu Kang planning area\n\nComputing G-function estimation\n\nset.seed(1234)\n\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nAfter the simulation is complete, we will then plot the graph.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nAgain, we will plot the graph.\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-f-function",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using F-Function",
    "text": "Analysing Spatial Point Process Using F-Function\nThe F-function measures the distances from randomly chosen locations in a study area to the nearest event (point) in the dataset and summarizes these distances across the entire area. In simple terms, it shows how close random locations are to the nearest points and whether events are widely spread out or leave large empty spaces.\nWe will be using Fest() for the computing of F-function and envelope() for the monte carlo simulation. These 2 functions are of the spatstat package.\n\nChoa Chu Kang planning area\n\nComputing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing F-function estimation\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-k-function",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using K-Function",
    "text": "Analysing Spatial Point Process Using K-Function\nThe K-function evaluates the spatial clustering or dispersion of points by comparing the observed number of neighboring points within a given distance to what would be expected under CSR. In simple terms, it shows whether points are more clustered or more evenly spread than random at different spatial scales.\nWe will be using Kest() for the computing of K-function and envelope() for the monte carlo simulation. These 2 functions are of the spatstat package.\n\nChoa Chu Kang planning area\n\nComputing K-function estimate\nThe code chunk below is used to compute F-function using Kest() of spatat package.\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-l-function",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using L-Function",
    "text": "Analysing Spatial Point Process Using L-Function\nThe L-function is a transformation of the K-function that makes it easier to interpret by stabilizing its variance. Instead of looking directly at the cumulative number of points within a distance, the L-function rescales the values so that under complete spatial randomness (CSR), the function should follow a straight 45-degree line. In simple terms, it helps detect clustering or dispersion more clearly and is easier to interpret visually than the K-function.\nWe will be using Lest() for the computing of L-function and envelope() for the monte carlo simulation. These 2 functions are of the spatstat package.\n\nChoa Chu Kang planning area\n\nComputing L Function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing L-function estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Plotting functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#install-and-launching-r-packages",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Install and launching R packages",
    "text": "Install and launching R packages\nThe code chunk below uses p_load() of pacman package to check if the following packages are installed in the computer. If they are, then they will be launched into R.\n\nsf - Provides the core tools for handling spatial data\ntmap - A package used for producing maps for visualisation\nreadr - A package for importing delimited text files\ntidyr - A package for tidying and reshaping data into a clean format\ndplyr - A package for wrangling and manipulating data\nrvest - A web scraping package to download and parse data from websites\n\nTo Note: readr, tidyr and dplyr are part of tidyverse package so there is no need to load these packages individually.\n\npacman::p_load(sf, tmap, tidyverse, rvest)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#datasets",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#datasets",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Datasets",
    "text": "Datasets\nThe following datasets will be used:\n\nMaster Plan 2019 Subzone Boundary (No Sea) kml data file (Master plan 2019)\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2024 csv file (respopagesextod2024)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#importing-geospatial-data-into-r",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Importing Geospatial Data into R",
    "text": "Importing Geospatial Data into R\nst_read() function of the sf package will be used to import MP14_SUBZONE_WEB_PL shapefile into mpsz.\n\nmpsz &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01b\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nTidying the Data\nA function called extract_kml_field is created to extract values such as REGION_N, PLN_AREA_N, SUBZONE_N, and SUBZONE_C from the HTML Description field. This is done using the code chunk below.\n\nextract_kml_field &lt;- function(html_text, field_name) {\n  if (is.na(html_text) || html_text == \"\") return(NA_character_)\n  \n  page &lt;- read_html(html_text)\n  rows &lt;- page %&gt;% html_elements(\"tr\")\n  \n  value &lt;- rows %&gt;%\n    keep(~ html_text2(html_element(.x, \"th\")) == field_name) %&gt;%\n    html_element(\"td\") %&gt;%\n    html_text2()\n  \n  if (length(value) == 0) NA_character_ else value\n}\n\nThe code chunk below then applies this function to create new columns REGION_N, PLN_AREA_N, SUBZONE_N, and SUBZONE_C in the dataset. The raw Name and Description fields are removed, and geometry is moved to the last column for better structure.\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(\n    REGION_N = map_chr(Description, extract_kml_field, \"REGION_N\"),\n    PLN_AREA_N = map_chr(Description, extract_kml_field, \"PLN_AREA_N\"),\n    SUBZONE_N = map_chr(Description, extract_kml_field, \"SUBZONE_N\"),\n    SUBZONE_C = map_chr(Description, extract_kml_field, \"SUBZONE_C\")\n  ) %&gt;%\n  select(-Name, -Description) %&gt;%\n  relocate(geometry, .after = last_col())\n\nWe can view the content using the following code chunk.\n\nmpsz\n\nSimple feature collection with 332 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\nFirst 10 features:\n         REGION_N    PLN_AREA_N           SUBZONE_N SUBZONE_C\n1  CENTRAL REGION   BUKIT MERAH          DEPOT ROAD    BMSZ12\n2  CENTRAL REGION   BUKIT MERAH         BUKIT MERAH    BMSZ02\n3  CENTRAL REGION        OUTRAM           CHINATOWN    OTSZ03\n4  CENTRAL REGION DOWNTOWN CORE             PHILLIP    DTSZ04\n5  CENTRAL REGION DOWNTOWN CORE       RAFFLES PLACE    DTSZ05\n6  CENTRAL REGION        OUTRAM        CHINA SQUARE    OTSZ04\n7  CENTRAL REGION   BUKIT MERAH         TIONG BAHRU    BMSZ10\n8  CENTRAL REGION DOWNTOWN CORE    BAYFRONT SUBZONE    DTSZ12\n9  CENTRAL REGION   BUKIT MERAH TIONG BAHRU STATION    BMSZ04\n10 CENTRAL REGION DOWNTOWN CORE       CLIFFORD PIER    DTSZ06\n                         geometry\n1  MULTIPOLYGON (((103.8145 1....\n2  MULTIPOLYGON (((103.8221 1....\n3  MULTIPOLYGON (((103.8438 1....\n4  MULTIPOLYGON (((103.8496 1....\n5  MULTIPOLYGON (((103.8525 1....\n6  MULTIPOLYGON (((103.8486 1....\n7  MULTIPOLYGON (((103.8311 1....\n8  MULTIPOLYGON (((103.8589 1....\n9  MULTIPOLYGON (((103.8283 1....\n10 MULTIPOLYGON (((103.8552 1...."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#importing-attribute-data-into-r",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Importing Attribute Data into R",
    "text": "Importing Attribute Data into R\nwe will import respopagesextod2024.csv file into RStudio and save the file into an tibble dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package using the following code chunk.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2024.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#data-preparation",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Data Preparation",
    "text": "Data Preparation\nBefore creating the thematic map, we need to prepare a data table with year 2020 values. The data table should include following variables:\n\nYOUNG - age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE - age group 25-29 until age group 60-64,\nAGED - age group 65 and above,\nTOTAL - all age group, and\nDEPENDENCY - the ratio between young and aged against economy active group\n\n\nData Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2024 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\nJoining the attribute data and geospatial data\nBefore performing the georelational join, we need to standardise the text format of the PA and SZ fields by converting all values to uppercase. This step is necessary because the current values contain a mix of upper- and lowercase letters, whereas the SUBZONE_N and PLN_AREA_N fields are already stored entirely in uppercase.\n\npopdata2024 &lt;- popdata2024 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nleft_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2024 &lt;- left_join(mpsz, popdata2024,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nFinally, writing after data preparation is completed into an rds file.\n\nwrite_rds(mpsz_pop2024, \"data/rds/mpsz_pop2024.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Choropleth Mapping Geospatial Data Using tmap",
    "text": "Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping is a technique used to represent enumeration units such as countries, provinces, states or census areas by filling them with patterns or graduated colors.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\nPlotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation. The following chunk code will be used for that.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\nqtm(shp = mpsz_pop2024, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nFrom the code above, we learn two key points:\n\ntmap_mode(“plot”) is used to create a static map. If we want an interactive map, we would use tmap_mode(“view”) instead.\nThe fill argument tells the map which attribute to display. In this case, the DEPENDENCY field.\n\n\n\nCreating a choropleth map by using tmap’s elements\nWhile qtm() is useful for creating choropleth maps quickly and easily, its main limitation is the lack of flexibility in controlling the aesthetics of individual layers. To produce a high-quality, publication-ready choropleth map as shown below, it is better to use tmap’s drawing elements, which offer much greater customisation.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nDrawing a base map\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2024) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2024)+\n  tm_polygons(fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nTo Note:\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is blues3 of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a choropleth map using tm_fill() and *tm_border()\ntm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the polygon features onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to the respective dependecy values but the boundaries are missing. To add the boundary of the planning subzones, tm_borders() will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders()\n\n\n\n\n\n\n\n\nLight-gray border lines have been added to the choropleth map using tm_borders(). The fill_alpha argument controls transparency, with values ranging from 0 (fully transparent) to 1 (fully opaque, default). In addition, tm_borders() also allows customisation of border appearance through three arguments: col to set the border colour, lwd to adjust the line width (default is 1), and lty to define the line type (default is “solid”).\n\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(col = \"grey60\",\n             lwd = 0.1,\n             lty = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\nData classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nPlotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\nPlotting choropleth map with custom break\nIn tmap, category breaks are usually set automatically. If we want to control them, we can use the breaks argument in tm_scale_intervals(). Breaks must include both a minimum and maximum value, so to create n categories, we need to provide n+1 break points in increasing order.\nBefore deciding on the break points, it’s good practice to check the descriptive statistics of the variable. For example, the code below shows a summary of the DEPENDENCY field:\n\nsummary(mpsz_pop2024$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1905  0.7450  0.8377  0.8738  0.9366 12.7500      94 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus (0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2024)+\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00))) +\n  tm_borders(fill_alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break. They are\nassigned to the highest interval\n\n\n\n\n\n\n\n\n\n\n\n\nColour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\nUsing ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of values as shown in the code chunk below.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, we just add a “-” prefix.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nCartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar(), tm_grid() and tm_credit() are used to add compass, scale bar, grid lines and data sources onto the choropleth map.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: data.gov.sg & singstat\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nMap Layout\nA map layout brings together all the elements of a map such as the background, frame, typography, scale, aspect ratio, etc. into a clear and cohesive presentation.\nWe can refine and customize the layout using the tm_layout() function. In the next 2 sections, we will explore the most commonly used arguments of this function, using the dependency choropleth map as an example.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_pos_auto_in() +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: data.gov.sg & singstat\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nMap style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"-brewer.greens\")) + \n  tm_borders(fill_alpha = 0.5) + \n  tmap_style(\"natural\")\n\nstyle set to \"natural\"\n\n\nother available styles are: \"white\" (tmap default), \"gray\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#drawing-small-multiple-choropleth-maps",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Drawing Small Multiple Choropleth Maps",
    "text": "Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also known as facet maps, consist of several maps arranged side by side or stacked vertically. They are particularly useful for visualizing how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby creating multiple stand-alone maps with tmap_arrange(), and\nby defining a group-by variable in tm_facets().\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nSmall multiple choropleth maps are created by assigning two variables to the visual variable using the code chunk below\n\ntm_shape(mpsz_pop2024) + \n  tm_polygons(\n    fill = c(\"YOUNG\", \"AGED\"),\n    fill.legend = \n      tm_legend(position = tm_pos_in(\n        \"right\", \"bottom\")),\n    fill.scale = tm_scale_intervals(\n      style = \"equal\", \n      n = 5,\n      values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tmap_style(\"natural\")\n\nstyle set to \"natural\"\n\n\nother available styles are: \"white\" (tmap default), \"gray\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\"\n\n\n\n\n\n\n\n\n\n\n\nBy arrange multiples choropleth maps in a grid layout\nmultiple choropleth maps are created and tmap_arrange() is used to arrange them in a grid layout.\n\nyoungmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"YOUNG\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                  item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of young population\")\n                \nagedmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"AGED\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n              style = \"quantile\", \n              values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of aged population\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\nMultiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2024) +\n  tm_fill(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\",\n            values = \"brewer.blues\")) + \n  tm_facets(by = \"REGION_N\",\n            nrow = 2, \n            ncols = 3,\n            free.coords=TRUE, \n            drop.units=TRUE) +\n  tm_layout(legend.show = TRUE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(fill_alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Mapping Spatial Object Meeting a Selection Criterion",
    "text": "Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use filter() of dplyr package to select geographical area of interest and plot a choropleth map focus only on the selected region.\n\nmpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\") %&gt;%\n  tm_shape() +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.greens\"),\n              fill.legend = tm_legend()) +\n  tm_borders(fill_alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#complementing-thematic-map-with-statistical-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#complementing-thematic-map-with-statistical-chart",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Complementing Thematic Map with Statistical Chart",
    "text": "Complementing Thematic Map with Statistical Chart\nMaps and charts work well together because they highlight different aspects of the same data. Maps are good for showing spatial patterns and relationships, while charts make it easy to see numbers, trends, and comparisons. Using both gives a clearer and more engaging view of the data.\nIn tmap, we can combine maps with statistical charts by using the fill.chart argument and the legend chart feature, as shown in the code chunk below.\n\nmpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\") %&gt;%\n  tm_shape() +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.greens\"),\n              fill.legend = tm_legend(),\n              fill.chart = tm_chart_box()) +\n  tm_borders() +\n  tm_layout(asp = 0.8)\n\n\n\n\n\n\n\n\nIn the code chunk below, We improve the visual representation further by highlighting and lebaling the outliers on the choropleth map.\n\nmpsz_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\n\nstats &lt;- boxplot.stats(mpsz_selected$DEPENDENCY)\n\noutlier_vals &lt;- stats$out\n\noutlier_sf &lt;- mpsz_selected[mpsz_selected$DEPENDENCY %in% outlier_vals, ]\n\ntm_shape(mpsz_selected) +\n  tm_polygons(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\", \n            values = \"brewer.blues\"),\n          fill.legend = tm_legend(),\n          fill.chart = tm_chart_box()) +\n  tm_borders(fill_alpha = 0.5) +\ntm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2) +\n  tm_text(\"SUBZONE_N\", col = \"red\", size = 0.7) +\n  tm_layout(asp = 0.8)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#creating-interactive-map",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#creating-interactive-map",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Creating Interactive Map",
    "text": "Creating Interactive Map\nInteractive maps allow users to explore data by zooming, panning, clicking on locations, and adding overlays, making the experience more dynamic than static maps. With tmap, you can easily switch between static and interactive views using tmap_mode(), depending on your analysis needs.\nThe code chunks below show how to build an interactive map.\n\nregion_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\nregion_bbox &lt;- st_bbox(region_selected)\n\nstats &lt;- boxplot.stats(region_selected$DEPENDENCY)\noutlier_vals &lt;- stats$out\noutlier_sf &lt;- region_selected[region_selected$DEPENDENCY %in% outlier_vals, ]\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(region_selected, \n         bbox = region_bbox) +\n  tm_fill(\"DEPENDENCY\",\n          id = \"SUBZONE_N\",\n          popup.vars = c(\n            \"Name\" = \"SUBZONE_N\", \n            \"Dependency\" = \"DEPENDENCY\")) +\n  tm_borders() +\n  tm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2)\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\nThe interactive map can be confusing if users zoom in and out too freely. To prevent this, the set_zoom_limits argument is used to restrict how far users can zoom in or out of the map.\n\nregion_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\nregion_bbox &lt;- st_bbox(region_selected)\n\nstats &lt;- boxplot.stats(region_selected$DEPENDENCY)\noutlier_vals &lt;- stats$out\noutlier_sf &lt;- region_selected[region_selected$DEPENDENCY %in% outlier_vals, ]\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(region_selected, \n         bbox = region_bbox) +\n  tm_fill(\"DEPENDENCY\",\n          id = \"SUBZONE_N\",\n          popup.vars = c(\n            \"Name\" = \"SUBZONE_N\", \n            \"Dependency\" = \"DEPENDENCY\")) +\n  tm_borders() +\n  tm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2) +\n  tm_view(set_zoom_limits = c(12,14))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\nThe following datasets will be used:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format (Master Plan 2014 Subzone Boundary)\nCyclingPath, a line feature layer in ESRI shapefile format (Cycling Path)\nPreSchool, a point feature layer in kml file format (Pre-Schools Location)\nLatest Airbnb Singapore Listing Data (Inside Airbnb)\n\n\n\n\nst_read() function of the sf package will be used to import MP14_SUBZONE_WEB_PL shapefile into mpsz.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe same function will be used to import the CyclingPath shapefile into cyclingpath as well.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4651 features and 19 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11721.1 ymin: 27550.13 xmax: 42809.37 ymax: 49702.59\nProjected CRS: SVY21\n\n\nSince the PreSchool file is in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\nst_geometry() extracts or set the geometry column of the object. In this case, we are accessing the spatial information stored in our objects.\nThe following code chunk is what we will use to extract from mpsz.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nBesides the basic geospatial feature information, we also would like to learn more about the associated attribute information stored in our data frame. We will use glimpse() to show more information of our mpsz object.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nSometimes we would like a quick look/preview of our object. In this case, we can use head() to preview both the attribute information and geometry values without printing the entire dataset.\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\nWe will now turn our attention to visualising the spatial features. Using plot() will give us a way to render the geospatial features stored in our object. By plotting the geometry, we will be able to see the shapes and boundaries that is in our data.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nAs shown, it has plotted all the attributes in our object. If we want to plot only the geometry outline, we will have to use the following code chunk.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nWe may also want to plot specific attributes from our object. In this case we can select the specific attribute that we would like to plot.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\nWe also may want to plot multiple layers to have more visualisation. In that case we can use the following chunk code which plots the preschool layer on top of the mpsz layer.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), \n     add = TRUE)\n\n\n\n\n\n\n\n\nThe preschool layer is not shown in this example. This is because the EPSG codes are different and each layer is using a different CRS format.\nTo ensure correct visualisation and analysis, it is necessary to transform all layers into a common CRS before plotting or overlaying them.\n\n\nAs shown above, the issue is due to the layers using different CRS format. We will proceed to check the CRS format of our mpsz using the following code chunk\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data frame shows SVY21, it shows that its EPSG code is 9001. Since the EPSG code should be 3414, we will proceed to assign the correct EPSG code using the following code chunk.\n\nmpsz &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWith that done, we can check the EPSG code again.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nEPSG code is now 3414.\n\n\n\nAs mentioned above, a common CRS is required. Without a common CRS, two layers plotted together will not align. As a result, features that should overlap may instead appear far apart or not visible in the same plotting window.\nBy ensuring a common CRS across all layers, we guarantee that every coordinate is interpreted in the same “language,” allowing features to align properly on the map.\nWe will proceed to transform the CRS for preschool to SVY21 with the following code chunk\n\npreschool &lt;- st_transform(preschool, \n                              crs = 3414)\n\nWith that done, we can now proceed to plot the layers.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), add = TRUE)\n\n\n\n\n\n\n\n\nBoth layers have been plotted properly.\n\n\n\n\n\n\nWe will now proceed to import the listings data from the Airbnb csv file.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3659 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (42): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPreviously, we used glimpse() to view our object which showed both attribute values and their data types.\nHowever, when we first import a CSV, it is not yet a spatial object. list() will allows use to view the object’s contents or structure in R’s base style. We can later apply glimpse() once the data is prepared for further analysis.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,659 × 79\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.03e13 2025-06-26   city … Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.03e13 2025-06-27   previ… B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.03e13 2025-06-27   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.03e13 2025-06-26   previ… 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.03e13 2025-06-27   previ… 15 m… Lovely hom…\n 6 294281 https://www.airbnb.co…   2.03e13 2025-06-30   city … 5 mi… I have 3 b…\n 7 324945 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Comf… **IMPORTAN…\n 8 330095 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Rela… **IMPORTAN…\n 9 344803 https://www.airbnb.co…   2.03e13 2025-06-25   city … Budg… Direct bus…\n10 369141 https://www.airbnb.co…   2.03e13 2025-06-26   city … 5min… A room in …\n# ℹ 3,649 more rows\n# ℹ 72 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\nAfter checking the information is correct, we can now choose to convert it into a dataframe.\n\n\n\nThe code chunk below converts the listing data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe may now view the data using glimpse().\n\nglimpse(listings_sf)\n\nRows: 3,659\nColumns: 78\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.025063e+13, 2.025063e+1…\n$ last_scraped                                 &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ source                                       &lt;chr&gt; \"city scrape\", \"previous …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 59, 59, 7, 59, 5…\n$ host_total_listings_count                    &lt;dbl&gt; 10, 10, 10, 88, 88, 8, 88…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 2, 1, 2, 1, 1, 2, 1, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; 1.0, NA, 0.5, NA, NA, 1.0…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, NA, 1, NA, NA, 2, NA, …\n$ beds                                         &lt;dbl&gt; 3, NA, 2, NA, NA, 1, NA, …\n$ amenities                                    &lt;chr&gt; \"[\\\"Shampoo\\\", \\\"Fire pit…\n$ price                                        &lt;chr&gt; \"$143.00\", NA, \"$76.00\", …\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 20, 30, 0, 0, 30, 0, …\n$ availability_60                              &lt;dbl&gt; 60, 49, 60, 24, 25, 60, 2…\n$ availability_90                              &lt;dbl&gt; 90, 79, 90, 54, 55, 90, 5…\n$ availability_365                             &lt;dbl&gt; 90, 79, 90, 153, 153, 365…\n$ calendar_last_scraped                        &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 131, …\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ availability_eoy                             &lt;dbl&gt; 90, 79, 90, 153, 153, 185…\n$ number_of_reviews_ly                         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_occupancy_l365d                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_revenue_l365d                      &lt;dbl&gt; 0, NA, 0, NA, NA, 0, NA, …\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 58, 58, 7, 58, 5…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 58, 58, 6, 58, 5…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.14, 0.27, 0.13, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nWith this, we can now plot the listings layer onto the mpsz layer using the following code chunk.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(listings_sf), add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\n\n\n\nThe function st_buffer() creates a new geometry by expanding (or contracting, if negative) the boundaries of existing features by a specified distance. The distance is measured in the units of the dataset’s CRS.\n\ncyclingpath &lt;- st_transform(cyclingpath, st_crs(mpsz))\nbuffer_cycling &lt;- st_buffer(\n  cyclingpath, dist=5, nQuadSegs = 30)\n\ndist = 5 creates a buffer distance of 5 units around each cycling path.\nnQuadSegs = 30 controls the smoothening of the curves. The higher the value, the smoother it is.\nNewly created buffer_cycling object contains polygons representing the buffered zones around each path with the same CRS as mpsz.\nCalculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved.\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\nmpsz_selected &lt;- mpsz %&gt;%\n  filter(SUBZONE_N == \"TAMPINES WEST\") \n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\nst_intersection() clips the cycling buffers so that only the parts within Tampines West remain\n\nbuffer_cycling_selected &lt;- st_intersection(\n  buffer_cycling, mpsz_selected)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nAfterwhich we plot the the selected area.\n\nplot(st_geometry(buffer_cycling_selected))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n\n\n\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\nst_intersects() returns us the features that intersect. This refers when two layers touch or overlap each other.\nSince the output of st_intersects() is a list, to summarise the results, we use length() to return the number of elements in an object which shows us the number of preschools that are within a subzone found from the result of st_intersects().\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))\n\nCheck the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nIn the code chunk below, another geoprocessing function of sf package called st_area() is used to derive the area of each planning subzone.\n\nmpsz$Area &lt;- mpsz %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\nWe will plot a histogram to reveal the distribution of Presch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz$`PreSch Density`)\n\n\n\n\n\n\n\n\nWe will use ggplot2 to provide a better output since it provides customisations.\n\nggplot(data=mpsz, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning subzones with a single pre-school, on the other hand, \\nthere are seven planning subzones with at least 30 or more pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nIn the code chunk below, appropriate ggplot2 functions are used to plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#datasets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#datasets",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The following datasets will be used:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format (Master Plan 2014 Subzone Boundary)\nCyclingPath, a line feature layer in ESRI shapefile format (Cycling Path)\nPreSchool, a point feature layer in kml file format (Pre-Schools Location)\nLatest Airbnb Singapore Listing Data (Inside Airbnb)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "st_read() function of the sf package will be used to import MP14_SUBZONE_WEB_PL shapefile into mpsz.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe same function will be used to import the CyclingPath shapefile into cyclingpath as well.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4651 features and 19 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11721.1 ymin: 27550.13 xmax: 42809.37 ymax: 49702.59\nProjected CRS: SVY21\n\n\nSince the PreSchool file is in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-contents-of-the-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-contents-of-the-dataframe",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "st_geometry() extracts or set the geometry column of the object. In this case, we are accessing the spatial information stored in our objects.\nThe following code chunk is what we will use to extract from mpsz.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nBesides the basic geospatial feature information, we also would like to learn more about the associated attribute information stored in our data frame. We will use glimpse() to show more information of our mpsz object.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nSometimes we would like a quick look/preview of our object. In this case, we can use head() to preview both the attribute information and geometry values without printing the entire dataset.\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "We will now turn our attention to visualising the spatial features. Using plot() will give us a way to render the geospatial features stored in our object. By plotting the geometry, we will be able to see the shapes and boundaries that is in our data.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nAs shown, it has plotted all the attributes in our object. If we want to plot only the geometry outline, we will have to use the following code chunk.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nWe may also want to plot specific attributes from our object. In this case we can select the specific attribute that we would like to plot.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\nWe also may want to plot multiple layers to have more visualisation. In that case we can use the following chunk code which plots the preschool layer on top of the mpsz layer.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), \n     add = TRUE)\n\n\n\n\n\n\n\n\nThe preschool layer is not shown in this example. This is because the EPSG codes are different and each layer is using a different CRS format.\nTo ensure correct visualisation and analysis, it is necessary to transform all layers into a common CRS before plotting or overlaying them.\n\n\nAs shown above, the issue is due to the layers using different CRS format. We will proceed to check the CRS format of our mpsz using the following code chunk\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data frame shows SVY21, it shows that its EPSG code is 9001. Since the EPSG code should be 3414, we will proceed to assign the correct EPSG code using the following code chunk.\n\nmpsz &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWith that done, we can check the EPSG code again.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nEPSG code is now 3414.\n\n\n\nAs mentioned above, a common CRS is required. Without a common CRS, two layers plotted together will not align. As a result, features that should overlap may instead appear far apart or not visible in the same plotting window.\nBy ensuring a common CRS across all layers, we guarantee that every coordinate is interpreted in the same “language,” allowing features to align properly on the map.\nWe will proceed to transform the CRS for preschool to SVY21 with the following code chunk\n\npreschool &lt;- st_transform(preschool, \n                              crs = 3414)\n\nWith that done, we can now proceed to plot the layers.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), add = TRUE)\n\n\n\n\n\n\n\n\nBoth layers have been plotted properly."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "We will now proceed to import the listings data from the Airbnb csv file.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3659 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (42): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPreviously, we used glimpse() to view our object which showed both attribute values and their data types.\nHowever, when we first import a CSV, it is not yet a spatial object. list() will allows use to view the object’s contents or structure in R’s base style. We can later apply glimpse() once the data is prepared for further analysis.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,659 × 79\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.03e13 2025-06-26   city … Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.03e13 2025-06-27   previ… B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.03e13 2025-06-27   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.03e13 2025-06-26   previ… 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.03e13 2025-06-27   previ… 15 m… Lovely hom…\n 6 294281 https://www.airbnb.co…   2.03e13 2025-06-30   city … 5 mi… I have 3 b…\n 7 324945 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Comf… **IMPORTAN…\n 8 330095 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Rela… **IMPORTAN…\n 9 344803 https://www.airbnb.co…   2.03e13 2025-06-25   city … Budg… Direct bus…\n10 369141 https://www.airbnb.co…   2.03e13 2025-06-26   city … 5min… A room in …\n# ℹ 3,649 more rows\n# ℹ 72 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\nAfter checking the information is correct, we can now choose to convert it into a dataframe.\n\n\n\nThe code chunk below converts the listing data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe may now view the data using glimpse().\n\nglimpse(listings_sf)\n\nRows: 3,659\nColumns: 78\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.025063e+13, 2.025063e+1…\n$ last_scraped                                 &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ source                                       &lt;chr&gt; \"city scrape\", \"previous …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 59, 59, 7, 59, 5…\n$ host_total_listings_count                    &lt;dbl&gt; 10, 10, 10, 88, 88, 8, 88…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 2, 1, 2, 1, 1, 2, 1, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; 1.0, NA, 0.5, NA, NA, 1.0…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, NA, 1, NA, NA, 2, NA, …\n$ beds                                         &lt;dbl&gt; 3, NA, 2, NA, NA, 1, NA, …\n$ amenities                                    &lt;chr&gt; \"[\\\"Shampoo\\\", \\\"Fire pit…\n$ price                                        &lt;chr&gt; \"$143.00\", NA, \"$76.00\", …\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 20, 30, 0, 0, 30, 0, …\n$ availability_60                              &lt;dbl&gt; 60, 49, 60, 24, 25, 60, 2…\n$ availability_90                              &lt;dbl&gt; 90, 79, 90, 54, 55, 90, 5…\n$ availability_365                             &lt;dbl&gt; 90, 79, 90, 153, 153, 365…\n$ calendar_last_scraped                        &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 131, …\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ availability_eoy                             &lt;dbl&gt; 90, 79, 90, 153, 153, 185…\n$ number_of_reviews_ly                         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_occupancy_l365d                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_revenue_l365d                      &lt;dbl&gt; 0, NA, 0, NA, NA, 0, NA, …\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 58, 58, 7, 58, 5…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 58, 58, 6, 58, 5…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.14, 0.27, 0.13, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nWith this, we can now plot the listings layer onto the mpsz layer using the following code chunk.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(listings_sf), add = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\n\n\n\nThe function st_buffer() creates a new geometry by expanding (or contracting, if negative) the boundaries of existing features by a specified distance. The distance is measured in the units of the dataset’s CRS.\n\ncyclingpath &lt;- st_transform(cyclingpath, st_crs(mpsz))\nbuffer_cycling &lt;- st_buffer(\n  cyclingpath, dist=5, nQuadSegs = 30)\n\ndist = 5 creates a buffer distance of 5 units around each cycling path.\nnQuadSegs = 30 controls the smoothening of the curves. The higher the value, the smoother it is.\nNewly created buffer_cycling object contains polygons representing the buffered zones around each path with the same CRS as mpsz.\nCalculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved.\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\nmpsz_selected &lt;- mpsz %&gt;%\n  filter(SUBZONE_N == \"TAMPINES WEST\") \n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\nst_intersection() clips the cycling buffers so that only the parts within Tampines West remain\n\nbuffer_cycling_selected &lt;- st_intersection(\n  buffer_cycling, mpsz_selected)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nAfterwhich we plot the the selected area.\n\nplot(st_geometry(buffer_cycling_selected))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n\n\n\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\nst_intersects() returns us the features that intersect. This refers when two layers touch or overlap each other.\nSince the output of st_intersects() is a list, to summarise the results, we use length() to return the number of elements in an object which shows us the number of preschools that are within a subzone found from the result of st_intersects().\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))\n\nCheck the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nIn the code chunk below, another geoprocessing function of sf package called st_area() is used to derive the area of each planning subzone.\n\nmpsz$Area &lt;- mpsz %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\nWe will plot a histogram to reveal the distribution of Presch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz$`PreSch Density`)\n\n\n\n\n\n\n\n\nWe will use ggplot2 to provide a better output since it provides customisations.\n\nggplot(data=mpsz, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning subzones with a single pre-school, on the other hand, \\nthere are seven planning subzones with at least 30 or more pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nIn the code chunk below, appropriate ggplot2 functions are used to plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis (SPPA) is the evaluation of the pattern or distribution of a set of points on a surface. The points may represent:\n\nEvents such as crimes, traffic accidents, or disease onsets, or\nBusiness services (e.g., coffee shops and fast-food outlets) or facilities such as childcare centres and eldercare centres.\n\nFirst-order Spatial Point Pattern Analysis (1st-SPPA) studies how point intensity (density) varies across space. This will help answer questions like:\n\nAre there more points in some areas than others?\nWhere are the hotspots or clusters?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#mapping-the-geospatial-data-sets",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Mapping the geospatial data sets",
    "text": "Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns. We will use the code chunk below to plot the map.\n\ntm_shape(mpsz_cl) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nTo note that the dots are all within the same map. This means the formats are in order which is very important. We may also apply a more interactive version using the following code chunk.\n\ntmap_mode('view')\n\nℹ tmap mode set to \"view\".\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\nRegistered S3 method overwritten by 'jsonify':\n  method     from    \n  print.json jsonlite\n\n\n\n\n\n\nTo set tmap back to plot.\n\ntmap_mode('plot')\n\nℹ tmap mode set to \"plot\".\n\n\nIn interactive mode, tmap uses the leaflet for R API. This lets us pan, zoom, and click on points to see details. We can also change the background map, with options like ESRI.WorldGrayCanvas (default), OpenStreetMap, and ESRI.WorldTopoMap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Geospatial Data wrangling",
    "text": "Geospatial Data wrangling\n\nConverting sf data frames to ppp class\nspatstat requires the point event data in ppp object form. The code chunk below uses as.ppp() of spatstat package to convert childcare_sf to ppp format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWe will use class() to verify the new object childcare_ppp.\n\nclass(childcare_ppp)\n\n[1] \"ppp\"\n\n\nThis confirms childcare_ppp is a ppp object class.\nWe may want to get a summary of the ppp object using the following code chunk\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nMark variables: Name, Description\nSummary:\n     Name           Description       \n Length:1925        Length:1925       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\nCreating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nas.owin() from spatstat wil be used to convert mpsz_cl into an owin object using the following code chunk.\n\nsg_owin &lt;- as.owin(mpsz_cl)\n\nWe can verify the object class again.\n\nclass(sg_owin)\n\n[1] \"owin\"\n\n\nAfter confirming the class, we may now use it for plotting.\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\nCombining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nchildcare_ppp is the dataset containing the childcare points whereas sg_owin contains the boundaries of Singapore as shown above. using [ ] we subset the points all within the Singapore boundary. childcareSG_ppp will be the new object containing the combination of both as shown below.\n\nchildcareSG_ppp\n\nMarked planar point pattern: 1925 points\nMark variables: Name, Description \nwindow: polygonal boundary\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#clark-evan-test-for-nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#clark-evan-test-for-nearest-neighbour-analysis",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Clark-Evan Test for Nearest Neighbour Analysis",
    "text": "Clark-Evan Test for Nearest Neighbour Analysis\nNearest Neighbor Analysis (NNA) is a spatial statistics method that calculates the average distance between each point and its closest neighbor to determine if a pattern of points is clustered, dispersed, or randomly distributed.\nClark-Evans test is a specific statistical method used within NNA to quantify whether a point pattern is clustered, random, or uniformly spaced, using the Clark-Evans aggregation index (R) to describe this pattern. NNA provides a numerical value that describes the degree of clustering or regularity, and the Clark-Evans test calculates a specific index (R) for this purpose.\nWe will perform Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of spatstat.explore package.\nThe test hypotheses are:\n\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\nclarkevans.test() of spatstat.explore package supports both with CSR and without CSR types of Clark-Evans test.\nCSR stands for Complete Spatial Randomness. It describes a distribution of points that is purely random without any points affecting the location of other points.\n\nPerform the Clark-Evans test without CSR\nWithout CSR compares the observed distribution of points to what would be expected under random placement, without adjusting for edge effects.\nThe code chunk below is the test without CSR.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"))\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nR = 0.53532, which is less than 1. This says that points are closer together which means there is clustering.\nFor Reference\nR = 1 -&gt; Pattern is consistent with CSR and is random\nR &lt; 1 -&gt; Points are close together meaning there is clustering\nR &gt; 1 -&gt; Points are further apart than random, potential regular spacing or dispersion\nP-value &lt; 2.2e-16 which is less than 0.05, we reject the null hypothesis of CSR. This shows that the clustering is statistically significant and unlikely due to chance/random.\nWith these results, it shows that childcare centres are not randomly distributed. In Singapore context, childcare centres tend to be clustered when regions have a higher population density.\n\n\nPerform the Clark-Evans test with CSR\nWith CSR adjusts for boundary effects. It applies edge corrections so that points near the boundary aren’t unfairly treated as having fewer neighbours. It is generally more accurate and recommended for real world spatial data with irregular shapes like Singapore.\nIn the code chunk below, the argument method = “MonteCarlo” is used. In this case, the p-value for the test is computed by comparing the observed value of R to the results obtained from nsim (i.e. 39, 99, 999) simulated realisations of Complete Spatial Randomness conditional on the observed number of points.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                method=\"MonteCarlo\",\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value = 0.01\nalternative hypothesis: clustered (R &lt; 1)\n\n\nR = 0.53532, same as above, this says that points are closer together which means there is clustering.\nP-value = 0.01, although higher than the previous result, still less than 0.05. We reject the CSR and conclude that the childcare centres are statistically clustered.\nSince we used a Monte Carlo test, we can assume the p-value is more realistic since its based on random simulations."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#kernel-density-estimation-method",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#kernel-density-estimation-method",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Kernel Density Estimation Method",
    "text": "Kernel Density Estimation Method\nKernel Density Estimation (KDE) is a valuable tool for visualising and analyzing first-order spatial point patterns. It is widely considered a method within Exploratory Spatial Data Analysis (ESDA) because it’s used to visualize and understand spatial data patterns by transforms discrete point data (like locations of childcare service, crime incidents or disease cases) into continuous density surfaces that reveal clusters and variations in event occurrences, without making prior assumptions about data distribution. It helps to begin understanding data distribution, identify hotspots, and explore relationships between spatial variables before performing more rigorous analysis.\n\nWorking with automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_SG_diggle &lt;- density(\n  childcareSG_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel=\"gaussian\") \n\nWe will use plot() to display the kernal density derived.\n\nplot(kde_SG_diggle)\n\n\n\n\n\n\n\n\nWe will use summary() to view the summary report.\n\nsummary(kde_SG_diggle)\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2667.538, 55941.94] x [21448.47, 50256.33] units\ndimensions of each pixel: 416 x 225.0614 units\nImage is defined on a subset of the rectangular grid\nSubset area = 669941961.12249 square units\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-6.584123e-21, 3.063698e-05]\n    integral = 1927.788\n    mean = 2.877545e-06\n\n\nWe can also retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n295.9712 \n\n\n\n\nRescalling KDE values\nIn the previous results, we had an output range as shown.\nrange = [-6.584123e-21, 3.063698e-05]\nThe default unit of measurement of SVY21 is in meters and as a result, the density values computed is in number of points per square meter. Hence, in the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp_km &lt;- rescale.ppp(\n  childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG_km &lt;- density(childcareSG_ppp_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nFinally, we can plot the kde object.\n\nplot(kde_childcareSG_km)\n\n\n\n\n\n\n\n\n\n\nWorking with different automatic bandwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\n\nbw.CvLbw.scottbw.pplbw.diggle\n\n\n\nbw.CvL(childcareSG_ppp_km)\n\n   sigma \n4.357209 \n\n\n\n\n\nbw.scott(childcareSG_ppp_km)\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\n\n\nbw.ppl(childcareSG_ppp_km)\n\n   sigma \n0.378997 \n\n\n\n\n\nbw.diggle(childcareSG_ppp_km)\n\n    sigma \n0.2959712 \n\n\n\n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because past experience shown that it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp_km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG_km, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\nWorking with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Fixed and Adaptive KDE",
    "text": "Fixed and Adaptive KDE\n\nComputing KDE by using fixed bandwidth\nWe will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp_km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_fb &lt;- density(childcareSG_ppp_km,\n                              sigma=0.6, \n                              edge=TRUE,\n                              kernel=\"gaussian\")\nplot(kde_childcareSG_fb)\n\n\n\n\n\n\n\n\n\n\nComputing KDE by using adaptive bandwidth\nThe fixed bandwidth method can be very sensitive when spatial point patterns are unevenly distributed, such as between urban and rural areas. To address this issue, an adaptive bandwidth approach can be used instead.\nWe can derive the adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_ab &lt;- adaptive.density(\n  childcareSG_ppp_km, \n  method=\"kernel\")\nplot(kde_childcareSG_ab)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG_fb, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_ab, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#plotting-cartographic-quality-kde-map",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#plotting-cartographic-quality-kde-map",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Plotting cartographic quality KDE map",
    "text": "Plotting cartographic quality KDE map\nwe will convert the im kernal density objects into SpatRaster object by using rast() of terra package.\n\nkde_childcareSG_bw_terra &lt;- rast(kde_childcareSG_km)\n\nChecking the class to confirm it is terra.\n\nclass(kde_childcareSG_bw_terra)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\n\nCan take a look at the file.\n\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \nsize        : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -5.824417e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\nWe note that coord. ref aka CRS is empty and will have to assign the CRS.\n\nAssigning projection systems\nThe code chunk below, crs() of terra is used to assign the CRS information on kde_childcareSG_bw_terra layer.\n\ncrs(kde_childcareSG_bw_terra) &lt;- \"EPSG:3414\"\n\nAgain to take a look at the object, and we have confirmed that the CRS is now SVY21.\n\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \nsize        : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. : SVY21 / Singapore TM (EPSG:3414) \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -5.824417e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\n\n\nPlotting KDE map with tmap\nWe will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_terra) + \n  tm_raster(col.scale = \n              tm_scale_continuous(\n                values = \"viridis\"),\n            col.legend = tm_legend(\n            title = \"Density values\",\n            title.size = 0.7,\n            text.size = 0.7,\n            bg.color = \"white\",\n            bg.alpha = 0.7,\n            position = tm_pos_in(\n              \"right\", \"bottom\"),\n            frame = TRUE)) +\n  tm_graticules(labels.size = 0.7) +\n  tm_compass() +\n  tm_layout(scale = 1.0)\n\n[plot mode] legend/component: Some components or legends are too \"high\" and are\ntherefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#first-order-sppa-at-the-planning-subzone-level",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#first-order-sppa-at-the-planning-subzone-level",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "First Order SPPA at the Planning Subzone Level",
    "text": "First Order SPPA at the Planning Subzone Level\nWe would like to further our analysis at the planning area level. For simplicity reason, we will focus on Punggol, Tampines Chua Chu Kand and Jurong West planning areas\n\nGeospatial data wrangling\nWe will use the following code chunk to extract the areas we want.\n\npg &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nWe will plot the areas extract for review as per good practice.\n\npar(mfrow=c(2,2))\nplot(st_geometry(pg), main = \"Ponggol\")\nplot(st_geometry(tm), main = \"Tampines\")\nplot(st_geometry(ck), main = \"Choa Chu Kang\")\nplot(st_geometry(jw), main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\nCreating owin object\nWe will now convert them to owin objects.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\nCombining point events object and owin object\n\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]\n\nrescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot the locations of the childcare centres into the 4 areas of focus.\n\npar(mfrow=c(2,2))\nplot(unmark(childcare_pg_ppp.km), \n  main=\"Punggol\")\nplot(unmark(childcare_tm_ppp.km), \n  main=\"Tampines\")\nplot(unmark(childcare_ck_ppp.km), \n  main=\"Choa Chu Kang\")\nplot(unmark(childcare_jw_ppp.km), \n  main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nClark and Evans Test\nThe code chunks below will be using clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in the areas of focus. The tests will be done without CSR.\n\nChoa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.84097, p-value = 0.008866\nalternative hypothesis: two-sided\n\n\n\n\nTampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.66817, p-value = 6.58e-12\nalternative hypothesis: two-sided\n\n\n\n\n\nComputing KDE surfaces by planning area\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "ISSS626-Geospatial-zytan",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],MEMBER[“World Geodetic System 1984 (G2296)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute and analyze spatial weights in R. Spatial weights are essential in spatial data analysis because they describe the structure of spatial relationships among geographical units such as neighborhoods, regions or districts. By defining which areas are considered “neighbors”, we can better understand how spatial dependence and spatial autocorrelation influence patterns in our data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#performing-relational-join",
    "title": "Spatial Weights and Applications",
    "section": "Performing relational join",
    "text": "Performing relational join\nAfter the importing of the files into the R environment, we will proceed to join the files.\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-queen-contiguity-based-neighbours",
    "title": "Spatial Weights and Applications",
    "section": "Computing (QUEEN) contiguity based neighbours",
    "text": "Computing (QUEEN) contiguity based neighbours\nThe following code chunk will be used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours. The percentage of nonzero weights of all possible pairs is about 5.79%. So this means that most regions are not neighbours. The most connected region, polygon 85, has 11 links.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. To see the neighbors for the first polygon in the object, we can use the following code chunk.\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below.\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo show the county names of its 5 neighboring polygons, the following code chunk will be used.\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"snap\")= num 9e-08\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#creating-rook-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#creating-rook-contiguity-based-neighbours",
    "title": "Spatial Weights and Applications",
    "section": "Creating (ROOK) contiguity based neighbours",
    "text": "Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 10 neighbours. There are two area units with only 1 neighbours.\nQueen contiguity defines neighbours as polygons that share either a border or a corner. Rook contiguity on the other hand is stricter. It only considers polygons as neighbours if they share a common border segment. Polygons that only touch at a single point are not neighbours under Rook. This is why the results differ and the queen contiguity usually has more neighbours per region."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-contiguity-weights",
    "title": "Spatial Weights and Applications",
    "section": "Visualising contiguity weights",
    "text": "Visualising contiguity weights\nTo create a connectivity graph, we need points that represent the polygons in our dataset. Since we are working with polygons, the most common way is to use their centroids (the center point of each polygon). These centroids give us a single coordinate (latitude and longitude) for each polygon, which we can then use to draw lines to their neighbouring polygons.\nSimply running st_centroid() on the polygons gives us the centroids, but for connectivity graphs we still need the coordinates. To do this, we use a mapping function that extracts the X (longitude) and Y (latitude) coordinates from each centroid and saves them into vectors. In this case, we use map_dbl() from the purrr package.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind() to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe can check the first few observations to see if they are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting the neighbours map\n\nQueen ContiguityRook ContiguityCombined\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#determine-the-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#determine-the-cut-off-distance",
    "title": "Spatial Weights and Applications",
    "section": "Determine the cut-off distance",
    "text": "Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nUse knearneigh() to find the k-nearest neighbours for each point.\nConvert the result into a neighbour list with knn2nb().\nMeasure neighbour distances with nbdist(), returned in coordinate units.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\n\nWarning in knn2nb(knearneigh(coords)): neighbour object has 25 sub-graphs\n\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report indicates that the maximum first nearest neighbour distance is 61.79 km. By setting this as the upper threshold, we can ensure that every unit will have at least one neighbour."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "title": "Spatial Weights and Applications",
    "section": "Computing fixed distance weight matrix",
    "text": "Computing fixed distance weight matrix\nWe will next compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nSince we used 62km based on our cut off distance which we have gotten from the previous step, each region on average has about 3 to 4 neighbours.\nWe can use str() or table() & card() of spdep package to display the content of wm_d62 weight matrix.\n\nstr()table() and card()\n\n\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\n\n\nWe will check the number of connected components in the list and show how many of such connected components are there.\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\nThis means that there is only 1 single connected component.\nWe can verify by checking how many regions are connected within this single connected component.\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\nThis means that all 88 regions are part of this single connected component.\n\nPlotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-adaptive-distance-weight-matrix",
    "title": "Spatial Weights and Applications",
    "section": "Computing adaptive distance weight matrix",
    "text": "Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\nPlotting distance based neighbours\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-with-row-standardized-weights",
    "title": "Spatial Weights and Applications",
    "section": "Spatial lag with row-standardized weights",
    "text": "Spatial lag with row-standardized weights\nWe will compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\nSpatially lagged values are values that represent the influence of neighbouring units on each spatial unit. Instead of looking only at a polygon’s own attribute, spatial lagging takes into account the attributes of its neighbours weighted by a spatial weights matrix (such as row-standardized weights or inverse distance weights from above).\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nThe comparison between the raw GDPPC map and the lagged GDPPC map highlights how spatial context changes the interpretation of regional values. The raw GDPPC map shows the individual economic performance of each region, which can sometimes create sharp contrasts between neighbouring areas. In contrast, the lagged GDPPC map smooths these extremes by averaging each region’s value with those of its neighbours, reducing variance and highlighting broader spatial patterns."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "Spatial Weights and Applications",
    "section": "Spatial lag as a sum of neighboring values",
    "text": "Spatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into our data frame.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nAfter the append, we can proceed to plot both the GDPPC and Spatial Lag Sum GDPPC for comparison.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-average",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-average",
    "title": "Spatial Weights and Applications",
    "section": "Spatial window average",
    "text": "Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nThe number of neighbors increases because include.self() explicitly adds the region to its own neighbor list since in spatial window average we want to include the value of the region itself along with its neighbors.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-sum",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-sum",
    "title": "Spatial Weights and Applications",
    "section": "Spatial window sum",
    "text": "Spatial window sum\nThe spatial window sum is similar to the spatial window average but differs in one key way: it does not apply row-standardized weights. Instead of averaging values across neighbors (and itself), it simply sums them.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nThe increase in neighbors here is also the same reason as the spatial window average.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nAnd append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window sum, kable() of knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class_Ex03",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse, httr, dplyr, lubridate)\n\nImporting the data\n\nfolder_path &lt;- \"data/aspatial/acra\"\nfile_list &lt;- list.files(path = folder_path,\n                        pattern = \"^ACRA*.*\\\\.csv$\",\n                        full.names = TRUE)\n\nacra_data &lt;- file_list %&gt;%\n  map_dfr(read_csv)\n\nRows: 166348 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 90920 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 135478 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 70351 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 83190 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 66990 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 81783 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 90798 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 58738 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 65251 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 73983 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 89064 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 118925 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 57432 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 39336 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 21124 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 95595 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 11790 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 67792 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 224176 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 136758 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 23592 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 35777 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 55774 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 12396 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 36391 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 17183 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (49): uen, issuance_agency_id, entity_name, entity_type_description, bu...\ndbl   (2): primary_ssic_code, no_of_officers\ndate  (2): registration_incorporation_date, uen_issue_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nSaving ACRA data\n\nwrite_rds(acra_data,\n          \"data/rds/acra_data.rds\")\n\nTidying ACRA data\nselect the target businesses by using SSIC code\nderive the year and month fields from registration_incorporation_date field\ntidy postal code values to avoid 5 digit\nWe need to confirm the postal code for those that are 5 digits. is the 0 supposed to be at the front or the back? we can confirm based on the address (street name).\n56111 refers to restaurants SSIC code\n\nbiz_56111 &lt;- acra_data%&gt;%\n  select(1:24) %&gt;%\n  filter(primary_ssic_code == 56111) %&gt;%\n  rename(date = registration_incorporation_date) %&gt;%\n  mutate(date = as.Date(date),\n         YEAR = year(date),\n         MONTH_NUM = month(date),\n         MONTH_ABBR = month(date,\n                            label = TRUE,\n                            abbr = TRUE)) %&gt;%\n  mutate(\n    postal_code = str_pad(postal_code,\n    width = 6, side = \"left\", pad = \"0\")) %&gt;%\n            filter(YEAR == 2025)\n\nGeocoding\nExtracting unique postal code from the postal_code field\n*dont geocode too many. at max 5000 records*\n\npostcodes &lt;- unique(biz_56111$postal_code)\n\nurl &lt;- \"https://onemap.gov.sg/api/common/elastic/search\"\n\nfound &lt;- data.frame()\nnot_found &lt;- data.frame(postcode = character())\n\nfor (pc in postcodes) {\n  query &lt;- list(\n    searchVal = pc,\n    returnGeom = \"Y\",\n    getAddrDetails = \"Y\",\n    pageNum = \"1\"\n  )\n  \n  res &lt;- GET(url, query = query)\n  json &lt;- content(res)\n  \n  if (json$found != 0) {\n    df &lt;- as.data.frame(json$results, stringAsFactors = FALSE)\n    df$input_postcode &lt;- pc\n    found &lt;- bind_rows(found, df)\n  } else{\n    not_found &lt;- bind_rows(not_found, data.frame(postcode = pc))\n  }\n}\n\nAppending the location information\n\nbiz_56111 = biz_56111 %&gt;%\n  left_join(found,\n            by = c('postal_code' = 'POSTAL'))\n\nconverting into SF data frame\n\nbiz_56111_sf &lt;- st_as_sf(biz_56111,\n                         coords = c(\"X\", \"Y\"),\n                         crs=3414)\n\n\nglimpse(biz_56111_sf)\n\nRows: 677\nColumns: 126\n$ uen                               &lt;chr&gt; \"202501136C\", \"202501329K\", \"2025029…\n$ issuance_agency_id                &lt;chr&gt; \"ACRA\", \"ACRA\", \"ACRA\", \"ACRA\", \"ACR…\n$ entity_name                       &lt;chr&gt; \"AL ASHIK PTE. LTD.\", \"ARASH LEGACY …\n$ entity_type_description           &lt;chr&gt; \"Local Company\", \"Local Company\", \"L…\n$ business_constitution_description &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ company_type_description          &lt;chr&gt; \"Exempt Private Company Limited by S…\n$ paf_constitution_description      &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ entity_status_description         &lt;chr&gt; \"Live Company\", \"Live Company\", \"Liv…\n$ date                              &lt;date&gt; 2025-01-08, 2025-01-09, 2025-01-19,…\n$ uen_issue_date                    &lt;date&gt; 2025-01-08, 2025-01-09, 2025-01-19,…\n$ address_type                      &lt;chr&gt; \"LOCAL\", \"LOCAL\", \"LOCAL\", \"LOCAL\", …\n$ block                             &lt;chr&gt; \"305D\", \"21\", \"324\", \"502\", \"15\", \"2…\n$ street_name                       &lt;chr&gt; \"ANCHORVALE LINK\", \"TAN QUEE LAN STR…\n$ level_no                          &lt;chr&gt; \"11\", \"02\", \"na\", \"02\", \"10\", \"na\", …\n$ unit_no                           &lt;chr&gt; \"23\", \"04\", \"na\", \"02\", \"32\", \"na\", …\n$ building_name                     &lt;chr&gt; \"ANCHORVALE PLACE\", \"HERITAGE PLACE\"…\n$ postal_code                       &lt;chr&gt; \"544305\", \"188108\", \"338822\", \"46902…\n$ other_address_line1               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ other_address_line2               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ account_due_date                  &lt;chr&gt; \"2026-08-31\", \"2026-07-31\", \"2026-07…\n$ annual_return_date                &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ primary_ssic_code                 &lt;dbl&gt; 56111, 56111, 56111, 56111, 56111, 5…\n$ primary_ssic_description          &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ primary_user_described_activity   &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ YEAR                              &lt;dbl&gt; 2025, 2025, 2025, 2025, 2025, 2025, …\n$ MONTH_NUM                         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, …\n$ MONTH_ABBR                        &lt;ord&gt; Jan, Jan, Jan, Jan, Jan, Jan, Feb, F…\n$ SEARCHVAL                         &lt;chr&gt; \"ANCHORVALE PLACE\", \"HERITAGE PLACE\"…\n$ BLK_NO                            &lt;chr&gt; \"305D\", \"21\", \"324\", \"502\", \"15\", \"2…\n$ ROAD_NAME                         &lt;chr&gt; \"ANCHORVALE LINK\", \"TAN QUEE LAN STR…\n$ BUILDING                          &lt;chr&gt; \"ANCHORVALE PLACE\", \"HERITAGE PLACE\"…\n$ ADDRESS                           &lt;chr&gt; \"305D ANCHORVALE LINK ANCHORVALE PLA…\n$ LATITUDE                          &lt;chr&gt; \"1.38903342950987\", \"1.2985892658367…\n$ LONGITUDE                         &lt;chr&gt; \"103.887299862674\", \"103.85640505809…\n$ input_postcode                    &lt;chr&gt; \"544305\", \"188108\", \"338822\", \"46902…\n$ SEARCHVAL.1                       &lt;chr&gt; NA, NA, \"324A LAVENDER STREET SINGAP…\n$ BLK_NO.1                          &lt;chr&gt; NA, NA, \"324A\", NA, NA, \"21A\", \"634\"…\n$ ROAD_NAME.1                       &lt;chr&gt; NA, NA, \"LAVENDER STREET\", NA, NA, \"…\n$ BUILDING.1                        &lt;chr&gt; NA, NA, \"NIL\", NA, NA, \"LITTLE INDIA…\n$ ADDRESS.1                         &lt;chr&gt; NA, NA, \"324A LAVENDER STREET SINGAP…\n$ POSTAL.1                          &lt;chr&gt; NA, NA, \"338822\", NA, NA, \"209894\", …\n$ X.1                               &lt;chr&gt; NA, NA, \"30900.419888882\", NA, NA, \"…\n$ Y.1                               &lt;chr&gt; NA, NA, \"33108.5793857146\", NA, NA, …\n$ LATITUDE.1                        &lt;chr&gt; NA, NA, \"1.31569661333886\", NA, NA, …\n$ LONGITUDE.1                       &lt;chr&gt; NA, NA, \"103.859380318427\", NA, NA, …\n$ SEARCHVAL.2                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BLK_NO.2                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ROAD_NAME.2                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BUILDING.2                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ADDRESS.2                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ POSTAL.2                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ X.2                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Y.2                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LATITUDE.2                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LONGITUDE.2                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ SEARCHVAL.3                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BLK_NO.3                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ROAD_NAME.3                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BUILDING.3                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ADDRESS.3                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ POSTAL.3                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ X.3                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Y.3                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LATITUDE.3                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LONGITUDE.3                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ SEARCHVAL.4                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BLK_NO.4                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ROAD_NAME.4                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BUILDING.4                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ADDRESS.4                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ POSTAL.4                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ X.4                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Y.4                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LATITUDE.4                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LONGITUDE.4                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ SEARCHVAL.5                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BLK_NO.5                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ROAD_NAME.5                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BUILDING.5                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ADDRESS.5                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ POSTAL.5                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ X.5                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Y.5                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LATITUDE.5                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LONGITUDE.5                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ SEARCHVAL.6                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BLK_NO.6                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ROAD_NAME.6                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BUILDING.6                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ADDRESS.6                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ POSTAL.6                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ X.6                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Y.6                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LATITUDE.6                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LONGITUDE.6                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ SEARCHVAL.7                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BLK_NO.7                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ROAD_NAME.7                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BUILDING.7                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ADDRESS.7                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ POSTAL.7                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ X.7                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Y.7                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LATITUDE.7                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LONGITUDE.7                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ SEARCHVAL.8                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BLK_NO.8                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ROAD_NAME.8                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BUILDING.8                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ADDRESS.8                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ POSTAL.8                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ X.8                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Y.8                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LATITUDE.8                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LONGITUDE.8                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ SEARCHVAL.9                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BLK_NO.9                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ROAD_NAME.9                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ BUILDING.9                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ADDRESS.9                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ POSTAL.9                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ X.9                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Y.9                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LATITUDE.9                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LONGITUDE.9                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ geometry                          &lt;POINT [m]&gt; POINT (34007.42 41217.84), POI…"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626-Geospatial-zytan",
    "section": "",
    "text": "Welcome to ISSS626 Geospatial Analytics and Applications. In this website, you will find my coursework prepared for this course."
  }
]