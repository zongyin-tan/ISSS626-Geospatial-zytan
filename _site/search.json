[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626-Geospatial-zytan",
    "section": "",
    "text": "Welcome to ISSS626 Geospatial Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "ISSS626-Geospatial-zytan",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],MEMBER[“World Geodetic System 1984 (G2296)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis (SPPA) is the evaluation of the pattern or distribution of a set of points on a surface. The points may represent:\n\nEvents such as crimes, traffic accidents, or disease onsets, or\nBusiness services (e.g., coffee shops and fast-food outlets) or facilities such as childcare centres and eldercare centres.\n\nFirst-order Spatial Point Pattern Analysis (1st-SPPA) studies how point intensity (density) varies across space. This will help answer questions like:\n\nAre there more points in some areas than others?\nWhere are the hotspots or clusters?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#mapping-the-geospatial-data-sets",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Mapping the geospatial data sets",
    "text": "Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns. We will use the code chunk below to plot the map.\n\ntm_shape(mpsz_cl) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nTo note that the dots are all within the same map. This means the formats are in order which is very important. We may also apply a more interactive version using the following code chunk.\n\ntmap_mode('view')\n\nℹ tmap mode set to \"view\".\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\nRegistered S3 method overwritten by 'jsonify':\n  method     from    \n  print.json jsonlite\n\n\n\n\n\n\nTo set tmap back to plot.\n\ntmap_mode('plot')\n\nℹ tmap mode set to \"plot\".\n\n\nIn interactive mode, tmap uses the leaflet for R API. This lets us pan, zoom, and click on points to see details. We can also change the background map, with options like ESRI.WorldGrayCanvas (default), OpenStreetMap, and ESRI.WorldTopoMap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Geospatial Data wrangling",
    "text": "Geospatial Data wrangling\n\nConverting sf data frames to ppp class\nspatstat requires the point event data in ppp object form. The code chunk below uses as.ppp() of spatstat package to convert childcare_sf to ppp format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWe will use class() to verify the new object childcare_ppp.\n\nclass(childcare_ppp)\n\n[1] \"ppp\"\n\n\nThis confirms childcare_ppp is a ppp object class.\nWe may want to get a summary of the ppp object using the following code chunk\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nMark variables: Name, Description\nSummary:\n     Name           Description       \n Length:1925        Length:1925       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\nCreating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nas.owin() from spatstat wil be used to convert mpsz_cl into an owin object using the following code chunk.\n\nsg_owin &lt;- as.owin(mpsz_cl)\n\nWe can verify the object class again.\n\nclass(sg_owin)\n\n[1] \"owin\"\n\n\nAfter confirming the class, we may now use it for plotting.\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\nCombining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nchildcare_ppp is the dataset containing the childcare points whereas sg_owin contains the boundaries of Singapore as shown above. using [ ] we subset the points all within the Singapore boundary. childcareSG_ppp will be the new object containing the combination of both as shown below.\n\nchildcareSG_ppp\n\nMarked planar point pattern: 1925 points\nMark variables: Name, Description \nwindow: polygonal boundary\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#clark-evan-test-for-nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#clark-evan-test-for-nearest-neighbour-analysis",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Clark-Evan Test for Nearest Neighbour Analysis",
    "text": "Clark-Evan Test for Nearest Neighbour Analysis\nNearest Neighbor Analysis (NNA) is a spatial statistics method that calculates the average distance between each point and its closest neighbor to determine if a pattern of points is clustered, dispersed, or randomly distributed.\nClark-Evans test is a specific statistical method used within NNA to quantify whether a point pattern is clustered, random, or uniformly spaced, using the Clark-Evans aggregation index (R) to describe this pattern. NNA provides a numerical value that describes the degree of clustering or regularity, and the Clark-Evans test calculates a specific index (R) for this purpose.\nWe will perform Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of spatstat.explore package.\nThe test hypotheses are:\n\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\nclarkevans.test() of spatstat.explore package supports both with CSR and without CSR types of Clark-Evans test.\nCSR stands for Complete Spatial Randomness. It describes a distribution of points that is purely random without any points affecting the location of other points.\n\nPerform the Clark-Evans test without CSR\nWithout CSR compares the observed distribution of points to what would be expected under random placement, without adjusting for edge effects.\nThe code chunk below is the test without CSR.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"))\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nR = 0.53532, which is less than 1. This says that points are closer together which means there is clustering.\nFor Reference\nR = 1 -&gt; Pattern is consistent with CSR and is random\nR &lt; 1 -&gt; Points are close together meaning there is clustering\nR &gt; 1 -&gt; Points are further apart than random, potential regular spacing or dispersion\nP-value &lt; 2.2e-16 which is less than 0.05, we reject the null hypothesis of CSR. This shows that the clustering is statistically significant and unlikely due to chance/random.\nWith these results, it shows that childcare centres are not randomly distributed. In Singapore context, childcare centres tend to be clustered when regions have a higher population density.\n\n\nPerform the Clark-Evans test with CSR\nWith CSR adjusts for boundary effects. It applies edge corrections so that points near the boundary aren’t unfairly treated as having fewer neighbours. It is generally more accurate and recommended for real world spatial data with irregular shapes like Singapore.\nIn the code chunk below, the argument method = “MonteCarlo” is used. In this case, the p-value for the test is computed by comparing the observed value of R to the results obtained from nsim (i.e. 39, 99, 999) simulated realisations of Complete Spatial Randomness conditional on the observed number of points.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                method=\"MonteCarlo\",\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value = 0.01\nalternative hypothesis: clustered (R &lt; 1)\n\n\nR = 0.53532, same as above, this says that points are closer together which means there is clustering.\nP-value = 0.01, although higher than the previous result, still less than 0.05. We reject the CSR and conclude that the childcare centres are statistically clustered.\nSince we used a Monte Carlo test, we can assume the p-value is more realistic since its based on random simulations."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#kernel-density-estimation-method",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#kernel-density-estimation-method",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Kernel Density Estimation Method",
    "text": "Kernel Density Estimation Method\nKernel Density Estimation (KDE) is a valuable tool for visualising and analyzing first-order spatial point patterns. It is widely considered a method within Exploratory Spatial Data Analysis (ESDA) because it’s used to visualize and understand spatial data patterns by transforms discrete point data (like locations of childcare service, crime incidents or disease cases) into continuous density surfaces that reveal clusters and variations in event occurrences, without making prior assumptions about data distribution. It helps to begin understanding data distribution, identify hotspots, and explore relationships between spatial variables before performing more rigorous analysis.\n\nWorking with automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_SG_diggle &lt;- density(\n  childcareSG_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel=\"gaussian\") \n\nWe will use plot() to display the kernal density derived.\n\nplot(kde_SG_diggle)\n\n\n\n\n\n\n\n\nWe will use summary() to view the summary report.\n\nsummary(kde_SG_diggle)\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2667.538, 55941.94] x [21448.47, 50256.33] units\ndimensions of each pixel: 416 x 225.0614 units\nImage is defined on a subset of the rectangular grid\nSubset area = 669941961.12249 square units\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-6.584123e-21, 3.063698e-05]\n    integral = 1927.788\n    mean = 2.877545e-06\n\n\nWe can also retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n295.9712 \n\n\n\n\nRescalling KDE values\nIn the previous results, we had an output range as shown.\nrange = [-6.584123e-21, 3.063698e-05]\nThe default unit of measurement of SVY21 is in meters and as a result, the density values computed is in number of points per square meter. Hence, in the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp_km &lt;- rescale.ppp(\n  childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG_km &lt;- density(childcareSG_ppp_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nFinally, we can plot the kde object.\n\nplot(kde_childcareSG_km)\n\n\n\n\n\n\n\n\n\n\nWorking with different automatic bandwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\n\nbw.CvLbw.scottbw.pplbw.diggle\n\n\n\nbw.CvL(childcareSG_ppp_km)\n\n   sigma \n4.357209 \n\n\n\n\n\nbw.scott(childcareSG_ppp_km)\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\n\n\nbw.ppl(childcareSG_ppp_km)\n\n   sigma \n0.378997 \n\n\n\n\n\nbw.diggle(childcareSG_ppp_km)\n\n    sigma \n0.2959712 \n\n\n\n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because past experience shown that it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp_km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG_km, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\nWorking with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Fixed and Adaptive KDE",
    "text": "Fixed and Adaptive KDE\n\nComputing KDE by using fixed bandwidth\nWe will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp_km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_fb &lt;- density(childcareSG_ppp_km,\n                              sigma=0.6, \n                              edge=TRUE,\n                              kernel=\"gaussian\")\nplot(kde_childcareSG_fb)\n\n\n\n\n\n\n\n\n\n\nComputing KDE by using adaptive bandwidth\nThe fixed bandwidth method can be very sensitive when spatial point patterns are unevenly distributed, such as between urban and rural areas. To address this issue, an adaptive bandwidth approach can be used instead.\nWe can derive the adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_ab &lt;- adaptive.density(\n  childcareSG_ppp_km, \n  method=\"kernel\")\nplot(kde_childcareSG_ab)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG_fb, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_ab, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#plotting-cartographic-quality-kde-map",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#plotting-cartographic-quality-kde-map",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "Plotting cartographic quality KDE map",
    "text": "Plotting cartographic quality KDE map\nwe will convert the im kernal density objects into SpatRaster object by using rast() of terra package.\n\nkde_childcareSG_bw_terra &lt;- rast(kde_childcareSG_km)\n\nChecking the class to confirm it is terra.\n\nclass(kde_childcareSG_bw_terra)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\n\nCan take a look at the file.\n\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \nsize        : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -5.824417e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\nWe note that coord. ref aka CRS is empty and will have to assign the CRS.\n\nAssigning projection systems\nThe code chunk below, crs() of terra is used to assign the CRS information on kde_childcareSG_bw_terra layer.\n\ncrs(kde_childcareSG_bw_terra) &lt;- \"EPSG:3414\"\n\nAgain to take a look at the object, and we have confirmed that the CRS is now SVY21.\n\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \nsize        : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. : SVY21 / Singapore TM (EPSG:3414) \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -5.824417e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\n\n\nPlotting KDE map with tmap\nWe will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_terra) + \n  tm_raster(col.scale = \n              tm_scale_continuous(\n                values = \"viridis\"),\n            col.legend = tm_legend(\n            title = \"Density values\",\n            title.size = 0.7,\n            text.size = 0.7,\n            bg.color = \"white\",\n            bg.alpha = 0.7,\n            position = tm_pos_in(\n              \"right\", \"bottom\"),\n            frame = TRUE)) +\n  tm_graticules(labels.size = 0.7) +\n  tm_compass() +\n  tm_layout(scale = 1.0)\n\n[plot mode] legend/component: Some components or legends are too \"high\" and are\ntherefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#first-order-sppa-at-the-planning-subzone-level",
    "href": "Hands-on_Ex/Hands-on_Ex02a/Hands-on_Ex02a.html#first-order-sppa-at-the-planning-subzone-level",
    "title": "First-order Spatial Point Patterns Analysis Methods",
    "section": "First Order SPPA at the Planning Subzone Level",
    "text": "First Order SPPA at the Planning Subzone Level\nWe would like to further our analysis at the planning area level. For simplicity reason, we will focus on Punggol, Tampines Chua Chu Kand and Jurong West planning areas\n\nGeospatial data wrangling\nWe will use the following code chunk to extract the areas we want.\n\npg &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nWe will plot the areas extract for review as per good practice.\n\npar(mfrow=c(2,2))\nplot(st_geometry(pg), main = \"Ponggol\")\nplot(st_geometry(tm), main = \"Tampines\")\nplot(st_geometry(ck), main = \"Choa Chu Kang\")\nplot(st_geometry(jw), main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\nCreating owin object\nWe will now convert them to owin objects.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\nCombining point events object and owin object\n\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]\n\nrescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot the locations of the childcare centres into the 4 areas of focus.\n\npar(mfrow=c(2,2))\nplot(unmark(childcare_pg_ppp.km), \n  main=\"Punggol\")\nplot(unmark(childcare_tm_ppp.km), \n  main=\"Tampines\")\nplot(unmark(childcare_ck_ppp.km), \n  main=\"Choa Chu Kang\")\nplot(unmark(childcare_jw_ppp.km), \n  main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nClark and Evans Test\nThe code chunks below will be using clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in the areas of focus. The tests will be done without CSR.\n\nChoa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.84097, p-value = 0.008866\nalternative hypothesis: two-sided\n\n\n\n\nTampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.66817, p-value = 6.58e-12\nalternative hypothesis: two-sided\n\n\n\n\n\nComputing KDE surfaces by planning area\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\nThe following datasets will be used:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format (Master Plan 2014 Subzone Boundary)\nCyclingPath, a line feature layer in ESRI shapefile format (Cycling Path)\nPreSchool, a point feature layer in kml file format (Pre-Schools Location)\nLatest Airbnb Singapore Listing Data (Inside Airbnb)\n\n\n\n\nst_read() function of the sf package will be used to import MP14_SUBZONE_WEB_PL shapefile into mpsz.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe same function will be used to import the CyclingPath shapefile into cyclingpath as well.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4651 features and 19 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11721.1 ymin: 27550.13 xmax: 42809.37 ymax: 49702.59\nProjected CRS: SVY21\n\n\nSince the PreSchool file is in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\nst_geometry() extracts or set the geometry column of the object. In this case, we are accessing the spatial information stored in our objects.\nThe following code chunk is what we will use to extract from mpsz.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nBesides the basic geospatial feature information, we also would like to learn more about the associated attribute information stored in our data frame. We will use glimpse() to show more information of our mpsz object.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nSometimes we would like a quick look/preview of our object. In this case, we can use head() to preview both the attribute information and geometry values without printing the entire dataset.\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\nWe will now turn our attention to visualising the spatial features. Using plot() will give us a way to render the geospatial features stored in our object. By plotting the geometry, we will be able to see the shapes and boundaries that is in our data.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nAs shown, it has plotted all the attributes in our object. If we want to plot only the geometry outline, we will have to use the following code chunk.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nWe may also want to plot specific attributes from our object. In this case we can select the specific attribute that we would like to plot.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\nWe also may want to plot multiple layers to have more visualisation. In that case we can use the following chunk code which plots the preschool layer on top of the mpsz layer.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), \n     add = TRUE)\n\n\n\n\n\n\n\n\nThe preschool layer is not shown in this example. This is because the EPSG codes are different and each layer is using a different CRS format.\nTo ensure correct visualisation and analysis, it is necessary to transform all layers into a common CRS before plotting or overlaying them.\n\n\nAs shown above, the issue is due to the layers using different CRS format. We will proceed to check the CRS format of our mpsz using the following code chunk\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data frame shows SVY21, it shows that its EPSG code is 9001. Since the EPSG code should be 3414, we will proceed to assign the correct EPSG code using the following code chunk.\n\nmpsz &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWith that done, we can check the EPSG code again.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nEPSG code is now 3414.\n\n\n\nAs mentioned above, a common CRS is required. Without a common CRS, two layers plotted together will not align. As a result, features that should overlap may instead appear far apart or not visible in the same plotting window.\nBy ensuring a common CRS across all layers, we guarantee that every coordinate is interpreted in the same “language,” allowing features to align properly on the map.\nWe will proceed to transform the CRS for preschool to SVY21 with the following code chunk\n\npreschool &lt;- st_transform(preschool, \n                              crs = 3414)\n\nWith that done, we can now proceed to plot the layers.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), add = TRUE)\n\n\n\n\n\n\n\n\nBoth layers have been plotted properly.\n\n\n\n\n\n\nWe will now proceed to import the listings data from the Airbnb csv file.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3659 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (42): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPreviously, we used glimpse() to view our object which showed both attribute values and their data types.\nHowever, when we first import a CSV, it is not yet a spatial object. list() will allows use to view the object’s contents or structure in R’s base style. We can later apply glimpse() once the data is prepared for further analysis.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,659 × 79\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.03e13 2025-06-26   city … Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.03e13 2025-06-27   previ… B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.03e13 2025-06-27   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.03e13 2025-06-26   previ… 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.03e13 2025-06-27   previ… 15 m… Lovely hom…\n 6 294281 https://www.airbnb.co…   2.03e13 2025-06-30   city … 5 mi… I have 3 b…\n 7 324945 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Comf… **IMPORTAN…\n 8 330095 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Rela… **IMPORTAN…\n 9 344803 https://www.airbnb.co…   2.03e13 2025-06-25   city … Budg… Direct bus…\n10 369141 https://www.airbnb.co…   2.03e13 2025-06-26   city … 5min… A room in …\n# ℹ 3,649 more rows\n# ℹ 72 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\nAfter checking the information is correct, we can now choose to convert it into a dataframe.\n\n\n\nThe code chunk below converts the listing data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe may now view the data using glimpse().\n\nglimpse(listings_sf)\n\nRows: 3,659\nColumns: 78\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.025063e+13, 2.025063e+1…\n$ last_scraped                                 &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ source                                       &lt;chr&gt; \"city scrape\", \"previous …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 59, 59, 7, 59, 5…\n$ host_total_listings_count                    &lt;dbl&gt; 10, 10, 10, 88, 88, 8, 88…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 2, 1, 2, 1, 1, 2, 1, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; 1.0, NA, 0.5, NA, NA, 1.0…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, NA, 1, NA, NA, 2, NA, …\n$ beds                                         &lt;dbl&gt; 3, NA, 2, NA, NA, 1, NA, …\n$ amenities                                    &lt;chr&gt; \"[\\\"Shampoo\\\", \\\"Fire pit…\n$ price                                        &lt;chr&gt; \"$143.00\", NA, \"$76.00\", …\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 20, 30, 0, 0, 30, 0, …\n$ availability_60                              &lt;dbl&gt; 60, 49, 60, 24, 25, 60, 2…\n$ availability_90                              &lt;dbl&gt; 90, 79, 90, 54, 55, 90, 5…\n$ availability_365                             &lt;dbl&gt; 90, 79, 90, 153, 153, 365…\n$ calendar_last_scraped                        &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 131, …\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ availability_eoy                             &lt;dbl&gt; 90, 79, 90, 153, 153, 185…\n$ number_of_reviews_ly                         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_occupancy_l365d                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_revenue_l365d                      &lt;dbl&gt; 0, NA, 0, NA, NA, 0, NA, …\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 58, 58, 7, 58, 5…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 58, 58, 6, 58, 5…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.14, 0.27, 0.13, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nWith this, we can now plot the listings layer onto the mpsz layer using the following code chunk.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(listings_sf), add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\n\n\n\nThe function st_buffer() creates a new geometry by expanding (or contracting, if negative) the boundaries of existing features by a specified distance. The distance is measured in the units of the dataset’s CRS.\n\ncyclingpath &lt;- st_transform(cyclingpath, st_crs(mpsz))\nbuffer_cycling &lt;- st_buffer(\n  cyclingpath, dist=5, nQuadSegs = 30)\n\ndist = 5 creates a buffer distance of 5 units around each cycling path.\nnQuadSegs = 30 controls the smoothening of the curves. The higher the value, the smoother it is.\nNewly created buffer_cycling object contains polygons representing the buffered zones around each path with the same CRS as mpsz.\nCalculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved.\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\nmpsz_selected &lt;- mpsz %&gt;%\n  filter(SUBZONE_N == \"TAMPINES WEST\") \n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\nst_intersection() clips the cycling buffers so that only the parts within Tampines West remain\n\nbuffer_cycling_selected &lt;- st_intersection(\n  buffer_cycling, mpsz_selected)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nAfterwhich we plot the the selected area.\n\nplot(st_geometry(buffer_cycling_selected))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n\n\n\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\nst_intersects() returns us the features that intersect. This refers when two layers touch or overlap each other.\nSince the output of st_intersects() is a list, to summarise the results, we use length() to return the number of elements in an object which shows us the number of preschools that are within a subzone found from the result of st_intersects().\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))\n\nCheck the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nIn the code chunk below, another geoprocessing function of sf package called st_area() is used to derive the area of each planning subzone.\n\nmpsz$Area &lt;- mpsz %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\nWe will plot a histogram to reveal the distribution of Presch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz$`PreSch Density`)\n\n\n\n\n\n\n\n\nWe will use ggplot2 to provide a better output since it provides customisations.\n\nggplot(data=mpsz, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning subzones with a single pre-school, on the other hand, \\nthere are seven planning subzones with at least 30 or more pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nIn the code chunk below, appropriate ggplot2 functions are used to plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#datasets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#datasets",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The following datasets will be used:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format (Master Plan 2014 Subzone Boundary)\nCyclingPath, a line feature layer in ESRI shapefile format (Cycling Path)\nPreSchool, a point feature layer in kml file format (Pre-Schools Location)\nLatest Airbnb Singapore Listing Data (Inside Airbnb)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "st_read() function of the sf package will be used to import MP14_SUBZONE_WEB_PL shapefile into mpsz.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe same function will be used to import the CyclingPath shapefile into cyclingpath as well.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4651 features and 19 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11721.1 ymin: 27550.13 xmax: 42809.37 ymax: 49702.59\nProjected CRS: SVY21\n\n\nSince the PreSchool file is in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-contents-of-the-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-contents-of-the-dataframe",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "st_geometry() extracts or set the geometry column of the object. In this case, we are accessing the spatial information stored in our objects.\nThe following code chunk is what we will use to extract from mpsz.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nBesides the basic geospatial feature information, we also would like to learn more about the associated attribute information stored in our data frame. We will use glimpse() to show more information of our mpsz object.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nSometimes we would like a quick look/preview of our object. In this case, we can use head() to preview both the attribute information and geometry values without printing the entire dataset.\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "We will now turn our attention to visualising the spatial features. Using plot() will give us a way to render the geospatial features stored in our object. By plotting the geometry, we will be able to see the shapes and boundaries that is in our data.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nAs shown, it has plotted all the attributes in our object. If we want to plot only the geometry outline, we will have to use the following code chunk.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nWe may also want to plot specific attributes from our object. In this case we can select the specific attribute that we would like to plot.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\nWe also may want to plot multiple layers to have more visualisation. In that case we can use the following chunk code which plots the preschool layer on top of the mpsz layer.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), \n     add = TRUE)\n\n\n\n\n\n\n\n\nThe preschool layer is not shown in this example. This is because the EPSG codes are different and each layer is using a different CRS format.\nTo ensure correct visualisation and analysis, it is necessary to transform all layers into a common CRS before plotting or overlaying them.\n\n\nAs shown above, the issue is due to the layers using different CRS format. We will proceed to check the CRS format of our mpsz using the following code chunk\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data frame shows SVY21, it shows that its EPSG code is 9001. Since the EPSG code should be 3414, we will proceed to assign the correct EPSG code using the following code chunk.\n\nmpsz &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWith that done, we can check the EPSG code again.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nEPSG code is now 3414.\n\n\n\nAs mentioned above, a common CRS is required. Without a common CRS, two layers plotted together will not align. As a result, features that should overlap may instead appear far apart or not visible in the same plotting window.\nBy ensuring a common CRS across all layers, we guarantee that every coordinate is interpreted in the same “language,” allowing features to align properly on the map.\nWe will proceed to transform the CRS for preschool to SVY21 with the following code chunk\n\npreschool &lt;- st_transform(preschool, \n                              crs = 3414)\n\nWith that done, we can now proceed to plot the layers.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), add = TRUE)\n\n\n\n\n\n\n\n\nBoth layers have been plotted properly."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "We will now proceed to import the listings data from the Airbnb csv file.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3659 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (42): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPreviously, we used glimpse() to view our object which showed both attribute values and their data types.\nHowever, when we first import a CSV, it is not yet a spatial object. list() will allows use to view the object’s contents or structure in R’s base style. We can later apply glimpse() once the data is prepared for further analysis.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,659 × 79\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.03e13 2025-06-26   city … Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.03e13 2025-06-27   previ… B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.03e13 2025-06-27   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.03e13 2025-06-26   previ… 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.03e13 2025-06-27   previ… 15 m… Lovely hom…\n 6 294281 https://www.airbnb.co…   2.03e13 2025-06-30   city … 5 mi… I have 3 b…\n 7 324945 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Comf… **IMPORTAN…\n 8 330095 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Rela… **IMPORTAN…\n 9 344803 https://www.airbnb.co…   2.03e13 2025-06-25   city … Budg… Direct bus…\n10 369141 https://www.airbnb.co…   2.03e13 2025-06-26   city … 5min… A room in …\n# ℹ 3,649 more rows\n# ℹ 72 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\nAfter checking the information is correct, we can now choose to convert it into a dataframe.\n\n\n\nThe code chunk below converts the listing data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe may now view the data using glimpse().\n\nglimpse(listings_sf)\n\nRows: 3,659\nColumns: 78\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.025063e+13, 2.025063e+1…\n$ last_scraped                                 &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ source                                       &lt;chr&gt; \"city scrape\", \"previous …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 59, 59, 7, 59, 5…\n$ host_total_listings_count                    &lt;dbl&gt; 10, 10, 10, 88, 88, 8, 88…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 2, 1, 2, 1, 1, 2, 1, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; 1.0, NA, 0.5, NA, NA, 1.0…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, NA, 1, NA, NA, 2, NA, …\n$ beds                                         &lt;dbl&gt; 3, NA, 2, NA, NA, 1, NA, …\n$ amenities                                    &lt;chr&gt; \"[\\\"Shampoo\\\", \\\"Fire pit…\n$ price                                        &lt;chr&gt; \"$143.00\", NA, \"$76.00\", …\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 20, 30, 0, 0, 30, 0, …\n$ availability_60                              &lt;dbl&gt; 60, 49, 60, 24, 25, 60, 2…\n$ availability_90                              &lt;dbl&gt; 90, 79, 90, 54, 55, 90, 5…\n$ availability_365                             &lt;dbl&gt; 90, 79, 90, 153, 153, 365…\n$ calendar_last_scraped                        &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 131, …\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ availability_eoy                             &lt;dbl&gt; 90, 79, 90, 153, 153, 185…\n$ number_of_reviews_ly                         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_occupancy_l365d                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_revenue_l365d                      &lt;dbl&gt; 0, NA, 0, NA, NA, 0, NA, …\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 58, 58, 7, 58, 5…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 58, 58, 6, 58, 5…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.14, 0.27, 0.13, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nWith this, we can now plot the listings layer onto the mpsz layer using the following code chunk.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(listings_sf), add = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\n\n\n\nThe function st_buffer() creates a new geometry by expanding (or contracting, if negative) the boundaries of existing features by a specified distance. The distance is measured in the units of the dataset’s CRS.\n\ncyclingpath &lt;- st_transform(cyclingpath, st_crs(mpsz))\nbuffer_cycling &lt;- st_buffer(\n  cyclingpath, dist=5, nQuadSegs = 30)\n\ndist = 5 creates a buffer distance of 5 units around each cycling path.\nnQuadSegs = 30 controls the smoothening of the curves. The higher the value, the smoother it is.\nNewly created buffer_cycling object contains polygons representing the buffered zones around each path with the same CRS as mpsz.\nCalculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved.\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\nmpsz_selected &lt;- mpsz %&gt;%\n  filter(SUBZONE_N == \"TAMPINES WEST\") \n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\nst_intersection() clips the cycling buffers so that only the parts within Tampines West remain\n\nbuffer_cycling_selected &lt;- st_intersection(\n  buffer_cycling, mpsz_selected)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nAfterwhich we plot the the selected area.\n\nplot(st_geometry(buffer_cycling_selected))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n\n\n\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\nst_intersects() returns us the features that intersect. This refers when two layers touch or overlap each other.\nSince the output of st_intersects() is a list, to summarise the results, we use length() to return the number of elements in an object which shows us the number of preschools that are within a subzone found from the result of st_intersects().\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))\n\nCheck the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nIn the code chunk below, another geoprocessing function of sf package called st_area() is used to derive the area of each planning subzone.\n\nmpsz$Area &lt;- mpsz %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\nWe will plot a histogram to reveal the distribution of Presch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz$`PreSch Density`)\n\n\n\n\n\n\n\n\nWe will use ggplot2 to provide a better output since it provides customisations.\n\nggplot(data=mpsz, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning subzones with a single pre-school, on the other hand, \\nthere are seven planning subzones with at least 30 or more pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nIn the code chunk below, appropriate ggplot2 functions are used to plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Plotting functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#install-and-launching-r-packages",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Install and launching R packages",
    "text": "Install and launching R packages\nThe code chunk below uses p_load() of pacman package to check if the following packages are installed in the computer. If they are, then they will be launched into R.\n\nsf - Provides the core tools for handling spatial data\ntmap - A package used for producing maps for visualisation\nreadr - A package for importing delimited text files\ntidyr - A package for tidying and reshaping data into a clean format\ndplyr - A package for wrangling and manipulating data\nrvest - A web scraping package to download and parse data from websites\n\nTo Note: readr, tidyr and dplyr are part of tidyverse package so there is no need to load these packages individually.\n\npacman::p_load(sf, tmap, tidyverse, rvest)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#datasets",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#datasets",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Datasets",
    "text": "Datasets\nThe following datasets will be used:\n\nMaster Plan 2019 Subzone Boundary (No Sea) kml data file (Master plan 2019)\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2024 csv file (respopagesextod2024)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#importing-geospatial-data-into-r",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Importing Geospatial Data into R",
    "text": "Importing Geospatial Data into R\nst_read() function of the sf package will be used to import MP14_SUBZONE_WEB_PL shapefile into mpsz.\n\nmpsz &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex01b\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nTidying the Data\nA function called extract_kml_field is created to extract values such as REGION_N, PLN_AREA_N, SUBZONE_N, and SUBZONE_C from the HTML Description field. This is done using the code chunk below.\n\nextract_kml_field &lt;- function(html_text, field_name) {\n  if (is.na(html_text) || html_text == \"\") return(NA_character_)\n  \n  page &lt;- read_html(html_text)\n  rows &lt;- page %&gt;% html_elements(\"tr\")\n  \n  value &lt;- rows %&gt;%\n    keep(~ html_text2(html_element(.x, \"th\")) == field_name) %&gt;%\n    html_element(\"td\") %&gt;%\n    html_text2()\n  \n  if (length(value) == 0) NA_character_ else value\n}\n\nThe code chunk below then applies this function to create new columns REGION_N, PLN_AREA_N, SUBZONE_N, and SUBZONE_C in the dataset. The raw Name and Description fields are removed, and geometry is moved to the last column for better structure.\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(\n    REGION_N = map_chr(Description, extract_kml_field, \"REGION_N\"),\n    PLN_AREA_N = map_chr(Description, extract_kml_field, \"PLN_AREA_N\"),\n    SUBZONE_N = map_chr(Description, extract_kml_field, \"SUBZONE_N\"),\n    SUBZONE_C = map_chr(Description, extract_kml_field, \"SUBZONE_C\")\n  ) %&gt;%\n  select(-Name, -Description) %&gt;%\n  relocate(geometry, .after = last_col())\n\nWe can view the content using the following code chunk.\n\nmpsz\n\nSimple feature collection with 332 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\nFirst 10 features:\n         REGION_N    PLN_AREA_N           SUBZONE_N SUBZONE_C\n1  CENTRAL REGION   BUKIT MERAH          DEPOT ROAD    BMSZ12\n2  CENTRAL REGION   BUKIT MERAH         BUKIT MERAH    BMSZ02\n3  CENTRAL REGION        OUTRAM           CHINATOWN    OTSZ03\n4  CENTRAL REGION DOWNTOWN CORE             PHILLIP    DTSZ04\n5  CENTRAL REGION DOWNTOWN CORE       RAFFLES PLACE    DTSZ05\n6  CENTRAL REGION        OUTRAM        CHINA SQUARE    OTSZ04\n7  CENTRAL REGION   BUKIT MERAH         TIONG BAHRU    BMSZ10\n8  CENTRAL REGION DOWNTOWN CORE    BAYFRONT SUBZONE    DTSZ12\n9  CENTRAL REGION   BUKIT MERAH TIONG BAHRU STATION    BMSZ04\n10 CENTRAL REGION DOWNTOWN CORE       CLIFFORD PIER    DTSZ06\n                         geometry\n1  MULTIPOLYGON (((103.8145 1....\n2  MULTIPOLYGON (((103.8221 1....\n3  MULTIPOLYGON (((103.8438 1....\n4  MULTIPOLYGON (((103.8496 1....\n5  MULTIPOLYGON (((103.8525 1....\n6  MULTIPOLYGON (((103.8486 1....\n7  MULTIPOLYGON (((103.8311 1....\n8  MULTIPOLYGON (((103.8589 1....\n9  MULTIPOLYGON (((103.8283 1....\n10 MULTIPOLYGON (((103.8552 1...."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#importing-attribute-data-into-r",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Importing Attribute Data into R",
    "text": "Importing Attribute Data into R\nwe will import respopagesextod2024.csv file into RStudio and save the file into an tibble dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package using the following code chunk.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2024.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#data-preparation",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Data Preparation",
    "text": "Data Preparation\nBefore creating the thematic map, we need to prepare a data table with year 2020 values. The data table should include following variables:\n\nYOUNG - age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE - age group 25-29 until age group 60-64,\nAGED - age group 65 and above,\nTOTAL - all age group, and\nDEPENDENCY - the ratio between young and aged against economy active group\n\n\nData Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2024 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\nJoining the attribute data and geospatial data\nBefore performing the georelational join, we need to standardise the text format of the PA and SZ fields by converting all values to uppercase. This step is necessary because the current values contain a mix of upper- and lowercase letters, whereas the SUBZONE_N and PLN_AREA_N fields are already stored entirely in uppercase.\n\npopdata2024 &lt;- popdata2024 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nleft_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2024 &lt;- left_join(mpsz, popdata2024,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nFinally, writing after data preparation is completed into an rds file.\n\nwrite_rds(mpsz_pop2024, \"data/rds/mpsz_pop2024.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Choropleth Mapping Geospatial Data Using tmap",
    "text": "Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping is a technique used to represent enumeration units such as countries, provinces, states or census areas by filling them with patterns or graduated colors.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\nPlotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation. The following chunk code will be used for that.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\nqtm(shp = mpsz_pop2024, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nFrom the code above, we learn two key points:\n\ntmap_mode(“plot”) is used to create a static map. If we want an interactive map, we would use tmap_mode(“view”) instead.\nThe fill argument tells the map which attribute to display. In this case, the DEPENDENCY field.\n\n\n\nCreating a choropleth map by using tmap’s elements\nWhile qtm() is useful for creating choropleth maps quickly and easily, its main limitation is the lack of flexibility in controlling the aesthetics of individual layers. To produce a high-quality, publication-ready choropleth map as shown below, it is better to use tmap’s drawing elements, which offer much greater customisation.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nDrawing a base map\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2024) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2024)+\n  tm_polygons(fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nTo Note:\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is blues3 of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a choropleth map using tm_fill() and *tm_border()\ntm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the polygon features onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to the respective dependecy values but the boundaries are missing. To add the boundary of the planning subzones, tm_borders() will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders()\n\n\n\n\n\n\n\n\nLight-gray border lines have been added to the choropleth map using tm_borders(). The fill_alpha argument controls transparency, with values ranging from 0 (fully transparent) to 1 (fully opaque, default). In addition, tm_borders() also allows customisation of border appearance through three arguments: col to set the border colour, lwd to adjust the line width (default is 1), and lty to define the line type (default is “solid”).\n\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(col = \"grey60\",\n             lwd = 0.1,\n             lty = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\nData classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nPlotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\nPlotting choropleth map with custom break\nIn tmap, category breaks are usually set automatically. If we want to control them, we can use the breaks argument in tm_scale_intervals(). Breaks must include both a minimum and maximum value, so to create n categories, we need to provide n+1 break points in increasing order.\nBefore deciding on the break points, it’s good practice to check the descriptive statistics of the variable. For example, the code below shows a summary of the DEPENDENCY field:\n\nsummary(mpsz_pop2024$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1905  0.7450  0.8377  0.8738  0.9366 12.7500      94 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus (0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2024)+\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00))) +\n  tm_borders(fill_alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break. They are\nassigned to the highest interval\n\n\n\n\n\n\n\n\n\n\n\n\nColour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\nUsing ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of values as shown in the code chunk below.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, we just add a “-” prefix.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nCartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar(), tm_grid() and tm_credit() are used to add compass, scale bar, grid lines and data sources onto the choropleth map.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: data.gov.sg & singstat\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nMap Layout\nA map layout brings together all the elements of a map such as the background, frame, typography, scale, aspect ratio, etc. into a clear and cohesive presentation.\nWe can refine and customize the layout using the tm_layout() function. In the next 2 sections, we will explore the most commonly used arguments of this function, using the dependency choropleth map as an example.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_pos_auto_in() +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: data.gov.sg & singstat\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nMap style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"-brewer.greens\")) + \n  tm_borders(fill_alpha = 0.5) + \n  tmap_style(\"natural\")\n\nstyle set to \"natural\"\n\n\nother available styles are: \"white\" (tmap default), \"gray\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#drawing-small-multiple-choropleth-maps",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Drawing Small Multiple Choropleth Maps",
    "text": "Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also known as facet maps, consist of several maps arranged side by side or stacked vertically. They are particularly useful for visualizing how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby creating multiple stand-alone maps with tmap_arrange(), and\nby defining a group-by variable in tm_facets().\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nSmall multiple choropleth maps are created by assigning two variables to the visual variable using the code chunk below\n\ntm_shape(mpsz_pop2024) + \n  tm_polygons(\n    fill = c(\"YOUNG\", \"AGED\"),\n    fill.legend = \n      tm_legend(position = tm_pos_in(\n        \"right\", \"bottom\")),\n    fill.scale = tm_scale_intervals(\n      style = \"equal\", \n      n = 5,\n      values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tmap_style(\"natural\")\n\nstyle set to \"natural\"\n\n\nother available styles are: \"white\" (tmap default), \"gray\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\"\n\n\n\n\n\n\n\n\n\n\n\nBy arrange multiples choropleth maps in a grid layout\nmultiple choropleth maps are created and tmap_arrange() is used to arrange them in a grid layout.\n\nyoungmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"YOUNG\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                  item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of young population\")\n                \nagedmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"AGED\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n              style = \"quantile\", \n              values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of aged population\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\nMultiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2024) +\n  tm_fill(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\",\n            values = \"brewer.blues\")) + \n  tm_facets(by = \"REGION_N\",\n            nrow = 2, \n            ncols = 3,\n            free.coords=TRUE, \n            drop.units=TRUE) +\n  tm_layout(legend.show = TRUE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(fill_alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Mapping Spatial Object Meeting a Selection Criterion",
    "text": "Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use filter() of dplyr package to select geographical area of interest and plot a choropleth map focus only on the selected region.\n\nmpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\") %&gt;%\n  tm_shape() +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.greens\"),\n              fill.legend = tm_legend()) +\n  tm_borders(fill_alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#complementing-thematic-map-with-statistical-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#complementing-thematic-map-with-statistical-chart",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Complementing Thematic Map with Statistical Chart",
    "text": "Complementing Thematic Map with Statistical Chart\nMaps and charts work well together because they highlight different aspects of the same data. Maps are good for showing spatial patterns and relationships, while charts make it easy to see numbers, trends, and comparisons. Using both gives a clearer and more engaging view of the data.\nIn tmap, we can combine maps with statistical charts by using the fill.chart argument and the legend chart feature, as shown in the code chunk below.\n\nmpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\") %&gt;%\n  tm_shape() +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.greens\"),\n              fill.legend = tm_legend(),\n              fill.chart = tm_chart_box()) +\n  tm_borders() +\n  tm_layout(asp = 0.8)\n\n\n\n\n\n\n\n\nIn the code chunk below, We improve the visual representation further by highlighting and lebaling the outliers on the choropleth map.\n\nmpsz_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\n\nstats &lt;- boxplot.stats(mpsz_selected$DEPENDENCY)\n\noutlier_vals &lt;- stats$out\n\noutlier_sf &lt;- mpsz_selected[mpsz_selected$DEPENDENCY %in% outlier_vals, ]\n\ntm_shape(mpsz_selected) +\n  tm_polygons(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\", \n            values = \"brewer.blues\"),\n          fill.legend = tm_legend(),\n          fill.chart = tm_chart_box()) +\n  tm_borders(fill_alpha = 0.5) +\ntm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2) +\n  tm_text(\"SUBZONE_N\", col = \"red\", size = 0.7) +\n  tm_layout(asp = 0.8)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#creating-interactive-map",
    "href": "Hands-on_Ex/Hands-on_Ex01b/Hands-on_Ex01b.html#creating-interactive-map",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "Creating Interactive Map",
    "text": "Creating Interactive Map\nInteractive maps allow users to explore data by zooming, panning, clicking on locations, and adding overlays, making the experience more dynamic than static maps. With tmap, you can easily switch between static and interactive views using tmap_mode(), depending on your analysis needs.\nThe code chunks below show how to build an interactive map.\n\nregion_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\nregion_bbox &lt;- st_bbox(region_selected)\n\nstats &lt;- boxplot.stats(region_selected$DEPENDENCY)\noutlier_vals &lt;- stats$out\noutlier_sf &lt;- region_selected[region_selected$DEPENDENCY %in% outlier_vals, ]\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(region_selected, \n         bbox = region_bbox) +\n  tm_fill(\"DEPENDENCY\",\n          id = \"SUBZONE_N\",\n          popup.vars = c(\n            \"Name\" = \"SUBZONE_N\", \n            \"Dependency\" = \"DEPENDENCY\")) +\n  tm_borders() +\n  tm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2)\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\nThe interactive map can be confusing if users zoom in and out too freely. To prevent this, the set_zoom_limits argument is used to restrict how far users can zoom in or out of the map.\n\nregion_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\nregion_bbox &lt;- st_bbox(region_selected)\n\nstats &lt;- boxplot.stats(region_selected$DEPENDENCY)\noutlier_vals &lt;- stats$out\noutlier_sf &lt;- region_selected[region_selected$DEPENDENCY %in% outlier_vals, ]\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(region_selected, \n         bbox = region_bbox) +\n  tm_fill(\"DEPENDENCY\",\n          id = \"SUBZONE_N\",\n          popup.vars = c(\n            \"Name\" = \"SUBZONE_N\", \n            \"Dependency\" = \"DEPENDENCY\")) +\n  tm_borders() +\n  tm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2) +\n  tm_view(set_zoom_limits = c(12,14))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Unlike First-order spatial point pattern, which looks at how point density varies across space, Second-order spatial point pattern analysis examines the relationships between points themselves. It asks whether points cluster together, spread out evenly or occur randomly.\nThis will help us answer questions like:\n\nAre the childcare centres in Singapore randomly distributed throughout the country?\nIf the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#preparation-of-master-plan-2019-subzone-no-sea-dataset",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#preparation-of-master-plan-2019-subzone-no-sea-dataset",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Preparation of Master Plan 2019 Subzone (No Sea) dataset",
    "text": "Preparation of Master Plan 2019 Subzone (No Sea) dataset\nThe dataset is prepared for the end result of an owin file called sg_owin.\n\n\nShow code\nextract_kml_field &lt;- function(html_text, field_name) {\n  if (is.na(html_text) || html_text == \"\") return(NA_character_)\n  \n  page &lt;- read_html(html_text)\n  rows &lt;- page %&gt;% html_elements(\"tr\")\n  \n  value &lt;- rows %&gt;%\n    keep(~ html_text2(html_element(.x, \"th\")) == field_name) %&gt;%\n    html_element(\"td\") %&gt;%\n    html_text2()\n  \n  if (length(value) == 0) NA_character_ else value\n}\n\nmpsz_sf &lt;- mpsz_sf %&gt;%\n  mutate(\n    REGION_N = map_chr(Description, extract_kml_field, \"REGION_N\"),\n    PLN_AREA_N = map_chr(Description, extract_kml_field, \"PLN_AREA_N\"),\n    SUBZONE_N = map_chr(Description, extract_kml_field, \"SUBZONE_N\"),\n    SUBZONE_C = map_chr(Description, extract_kml_field, \"SUBZONE_C\")\n  ) %&gt;%\n  select(-Name, -Description) %&gt;%\n  relocate(geometry, .after = last_col())\n\nmpsz_cl &lt;- mpsz_sf %&gt;%\n  filter(SUBZONE_N != \"SOUTHERN GROUP\",\n         PLN_AREA_N != \"WESTERN ISLANDS\",\n         PLN_AREA_N != \"NORTH-EASTERN ISLANDS\")\n\nsg_owin &lt;- as.owin(mpsz_cl)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#preparation-of-childcare-centre-dataset",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#preparation-of-childcare-centre-dataset",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Preparation of childcare centre dataset",
    "text": "Preparation of childcare centre dataset\nThe dataset is prepared for the end result of a ppp file. sg_owin file is combined into the data points of childcare_ppp file.\n\n\nShow code\nchildcare_sf &lt;- st_read(\"data/ChildCareServices.kml\") %&gt;% \n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `CHILDCARE' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex02b\\data\\ChildCareServices.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nShow code\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nchildcareSG_ppp = childcare_ppp[sg_owin]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-g-function",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using G-Function",
    "text": "Analysing Spatial Point Process Using G-Function\nThe G-function measures the distances from each point in a dataset to its nearest neighboring point and summarizes these distances across the study area. In simple terms, it shows how close points are to each other and whether they tend to cluster or spread out.\nWe will be using Gest() for the computing of G-function and envelope() for the monte carlo simulation. These 2 functions are of the spatstat package.\n\nChoa Chu Kang planning area\n\nComputing G-function estimation\n\nset.seed(1234)\n\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nAfter the simulation is complete, we will then plot the graph.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nAgain, we will plot the graph.\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-f-function",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using F-Function",
    "text": "Analysing Spatial Point Process Using F-Function\nThe F-function measures the distances from randomly chosen locations in a study area to the nearest event (point) in the dataset and summarizes these distances across the entire area. In simple terms, it shows how close random locations are to the nearest points and whether events are widely spread out or leave large empty spaces.\nWe will be using Fest() for the computing of F-function and envelope() for the monte carlo simulation. These 2 functions are of the spatstat package.\n\nChoa Chu Kang planning area\n\nComputing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing F-function estimation\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-k-function",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using K-Function",
    "text": "Analysing Spatial Point Process Using K-Function\nThe K-function evaluates the spatial clustering or dispersion of points by comparing the observed number of neighboring points within a given distance to what would be expected under CSR. In simple terms, it shows whether points are more clustered or more evenly spread than random at different spatial scales.\nWe will be using Kest() for the computing of K-function and envelope() for the monte carlo simulation. These 2 functions are of the spatstat package.\n\nChoa Chu Kang planning area\n\nComputing K-function estimate\nThe code chunk below is used to compute F-function using Kest() of spatat package.\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex02b/Hands-on_Ex02b.html#analysing-spatial-point-process-using-l-function",
    "title": "2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using L-Function",
    "text": "Analysing Spatial Point Process Using L-Function\nThe L-function is a transformation of the K-function that makes it easier to interpret by stabilizing its variance. Instead of looking directly at the cumulative number of points within a distance, the L-function rescales the values so that under complete spatial randomness (CSR), the function should follow a straight 45-degree line. In simple terms, it helps detect clustering or dispersion more clearly and is easier to interpret visually than the K-function.\nWe will be using Lest() for the computing of L-function and envelope() for the monte carlo simulation. These 2 functions are of the spatstat package.\n\nChoa Chu Kang planning area\n\nComputing L Function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing L-function estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called a space-time point process) is a random set of points where each point represents both the location and the time of an event. Examples include disease cases, species sightings or births, and natural hazards such as fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nWith the rapid growth of data that is tagged by both location and time, analyzing spatio-temporal point patterns has become increasingly important across many fields. In the past decade, several methods for such analysis have been developed and implemented in R. This chapter demonstrates how different R packages can be combined to carry out spatio-temporal point pattern analysis in a practical and intuitive way using real-world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1 January to 31 December 2023."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-study-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-study-area",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Importing study area",
    "text": "Importing study area\nThe code chunk below will be used to import the study area Kepulauan Bangka Belitung into the R environment.\n\nkbb &lt;- st_read(dsn=\"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") \n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex03\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 297 features and 26 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nkbb_sf &lt;- st_read(dsn=\"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\Users\\zongy\\OneDrive\\Desktop\\SMU\\ISSS626 - Geospatial Analytics\\zongyin-tan\\ISSS626-Geospatial-zytan\\Hands-on_Ex\\Hands-on_Ex03\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 297 features and 26 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\nclass(kbb_owin)\n\n[1] \"owin\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overall-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overall-plot",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Overall plot",
    "text": "Overall plot\nBelow is the code chunk used to plot the fire points onto the map.\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-geographic-distribution-of-forest-fires-by-month",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-geographic-distribution-of-forest-fires-by-month",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Visualising geographic distribution of forest fires by month",
    "text": "Visualising geographic distribution of forest fires by month\nBelow is the fire distribution points for each month of the year which is split using the Month_fac column. The following code chunk will be used for the visualisation.\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\ntm_facets(by=\"Month_fac\", \n            free.coords=FALSE, \n            drop.units = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#extracting-forest-fires-by-month",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#extracting-forest-fires-by-month",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Extracting forest fires by month",
    "text": "Extracting forest fires by month\nppp files only require the geometry (spatial locations) and/or marks (the attributes linked to each point) fields. Hence the following code chunk will be used to drop all non required fields.\n\nfire_month &lt;- fire_sf %&gt;% \n  select(Month_num)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-ppp",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-ppp",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Creating ppp",
    "text": "Creating ppp\nAfter cleaning is completed, we will then proceed to create the ppp object based on the months using the following code chunk.\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\nWe can use summary() to check our newly created ppp object.\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\nWe will need to check if there is any duplicated points as well using the following code chunk.\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#including-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#including-owin-object",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Including Owin object",
    "text": "Including Owin object\nWe will now merge the layers fire_month_ppp which contains the fire points and kbb_owin which is the map layer together into a new object fire_month_owin.\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.42469e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 47493 vertices\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533600000 square units\nFraction of frame area: 0.334\n\n\nWe will then proceed to plot the newly created object to check for correctness.\n\nplot(fire_month_owin)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-spatio-temporal-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-spatio-temporal-kde",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Computing Spatio-temporal KDE",
    "text": "Computing Spatio-temporal KDE\nUsing spattemp.density(), we compute the STKDE.\nThe resulting density surface provides insight into when and where fire occurrences were most concentrated, highlighting the patterns of fire activity.\n\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-spatio-temporal-kde-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-spatio-temporal-kde-object",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Plotting the spatio-temporal KDE object",
    "text": "Plotting the spatio-temporal KDE object\nWe will use plot() on the KDE between July 2023 to Decemeber 2023 for visualisation.\n\ntims &lt;- c(7,8,9,10,11,12)\npar(mfcol=c(2,3), mar=c(4,4,4,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at month\",i),\n       cex.main=1.2)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-ppp-object-including-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-ppp-object-including-owin-object",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Creating ppp object + Including Owin object",
    "text": "Creating ppp object + Including Owin object\nThe following code chunk will be used to create the ppp object based on the DayofYear field afterwhich we will create our owin object by merging and layers. Finally it will provide us the summary of our owin file.\n\nfire_yday_ppp &lt;- fire_sf %&gt;% \n  select(DayofYear) %&gt;%\n  as.ppp()\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\nsummary(fire_yday_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.42469e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   213.0   258.0   245.9   287.0   352.0 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 47493 vertices\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533600000 square units\nFraction of frame area: 0.334\n\n\nWe will next use spattemp.density() to compute the STKDE.\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 6.3198 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [3.959516e-27, 2.751287e-12]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-output-spatio-temporal-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-output-spatio-temporal-kde",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Plotting the output spatio-temporal KDE",
    "text": "Plotting the output spatio-temporal KDE\nFinally, we plot our KDE\n\nplot(kde_yday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-spatio-temporal-kde-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-spatio-temporal-kde-1",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Computing spatio-temporal KDE",
    "text": "Computing spatio-temporal KDE\nWith the h and lambda values derived from BOOT.spattemp(), we can use them to compute our STKDE with the following code chunk.\n\nkde_yday &lt;- spattemp.density(fire_yday_owin,\n                             h = 9000,\n                             lambda = 19)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 9000 (spatial)\n  lambda = 19 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [2.001642e-19, 2.445724e-12]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-output-spatio-temporal-kde-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotting-the-output-spatio-temporal-kde-1",
    "title": "Spatio-Temporal Point Patterns Analysis",
    "section": "Plotting the output spatio-temporal KDE",
    "text": "Plotting the output spatio-temporal KDE\nFinally we can plot with our newly computed KDE.\n\nplot(kde_yday)"
  }
]