---
title: "Spatial Weights and Applications"
format: html
---

# **Overview**

In this hands-on exercise, you will learn how to compute and analyze spatial weights in R. Spatial weights are essential in spatial data analysis because they describe the structure of spatial relationships among geographical units such as neighborhoods, regions or districts. By defining which areas are considered “neighbors”, we can better understand how spatial dependence and spatial autocorrelation influence patterns in our data.

# **The Study Area and Data**

Two data sets will be used in this hands-on exercise, they are:

-   Hunan county boundary layer. This is a geospatial data set in ESRI shapefile format.

-   Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.

# **Installing and Loading the R packages**

::: panel-tabset
## Packages Used

-   **sf** Provides the core tools for handling spatial data
-   **tmap** A package used for producing maps for visualisation
-   **tidyverse** A collection of R packages designed for data science tasks such as data import, cleaning, transformation, and visualisation
-   **spdep** Provides functions for spatial dependence and spatial regression analysis, including tools for creating spatial weights, testing for spatial autocorrelation, and fitting spatial econometric models
-   **knitr** Provides tools to integrate R code with documents written in R Markdown, LaTeX, or HTML. It allows you to run R code chunks directly inside a document and automatically insert the results into a report.

## Code Chunk

The code chunk below uses *p_load()* of pacman package to check if the packages are installed in the computer. If they are, then they will be launched into R.

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, knitr)
```
:::

# **Importing and Preparing Study Area**

::: panel-tabset
## **Importing hunan files**

The following code chunk will be using the *st_read()* function of sf package to import the Hunan shapefile into our R object, **hunan**.

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

## Importing csv files

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```
:::

## **Performing relational join**

After the importing of the files into the R environment, we will proceed to join the files.

The code chunk below will be used to update the attribute table of *hunan*’s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using *left_join()* of **dplyr** package.

```{r}
hunan <- left_join(hunan,hunan2012) %>%
  select(1:4, 7, 15)
```

# **Visualising Regional Development Indicator**

We will prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using *qtm()* of **tmap** package.

```{r}
basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size=0.25)

gdppc <- qtm(hunan, "GDPPC") +
  tm_layout(
    legend.position = c("left", "bottom"))
tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```

# **Computing Contiguity Spatial Weights**

we explore how to use the *poly2nb()* function from the **spdep** package to compute contiguity based spatial weight matrices for the study area. This function identifies neighbouring regions by checking for shared boundaries. The argument "queen" can be set to either TRUE or FALSE. When queen = TRUE, neighbours are defined using the Queen criterion (regions that share either a boundary or a corner are considered neighbours). If queen = FALSE, the function applies the Rook criterion, where only regions sharing a common border are treated as neighbours. By default, queen = TRUE.

## **Computing (QUEEN) contiguity based neighbours**

The following code chunk will be used to compute Queen contiguity weight matrix.

```{r}
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours. The percentage of nonzero weights of all possible pairs is about 5.79%. So this means that most regions are not neighbours. The most connected region, polygon 85, has 11 links.

For each polygon in our polygon object, *wm_q* lists all neighboring polygons. To see the neighbors for the first polygon in the object, we can use the following code chunk.

```{r}
wm_q[[1]]
```

Polygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.

We can retrive the county name of Polygon ID=1 by using the code chunk below.

```{r}
hunan$County[1]
```

The output reveals that Polygon ID=1 is Anxiang county.

To show the county names of its 5 neighboring polygons, the following code chunk will be used.

```{r}
hunan$NAME_3[c(2,3,4,57,85)]
```

We can retrieve the GDPPC of these five countries by using the code chunk below.

```{r}
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```

The printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.

You can display the complete weight matrix by using *str()*.

```{r}
str(wm_q)
```

## **Creating (ROOK) contiguity based neighbours**

The code chunk below is used to compute Rook contiguity weight matrix.

```{r}
wm_r <- poly2nb(hunan, queen=FALSE)
summary(wm_r)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 10 neighbours. There are two area units with only 1 neighbours.

**Queen contiguity** defines neighbours as polygons that **share either a border or a corner**. **Rook contiguity** on the other hand is stricter. It only considers polygons as neighbours if they **share a common border segment**. Polygons that only touch at a single point are **not neighbours** under Rook. This is why the results differ and the queen contiguity usually has more neighbours per region.

## **Visualising contiguity weights**

To create a connectivity graph, we need points that represent the polygons in our dataset. Since we are working with polygons, the most common way is to use their centroids (the center point of each polygon). These centroids give us a single coordinate (latitude and longitude) for each polygon, which we can then use to draw lines to their neighbouring polygons.

Simply running *st_centroid()* on the polygons gives us the centroids, but for connectivity graphs we still need the coordinates. To do this, we use a mapping function that extracts the X (longitude) and Y (latitude) coordinates from each centroid and saves them into vectors. In this case, we use *map_dbl()* from the **purrr** package.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

We do the same for latitude with one key difference. We access the second value per each centroid with \[\[2\]\].

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Now that we have latitude and longitude, we use *cbind()* to put longitude and latitude into the same object.

```{r}
coords <- cbind(longitude, latitude)
```

We can check the first few observations to see if they are formatted correctly.

```{r}
head(coords)
```

### Plotting the neighbours map

::: panel-tabset
## Queen Contiguity

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
```

## Rook Contiguity

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

## Combined

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="Queen Contiguity")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
plot(hunan$geometry, border="lightgrey", main="Rook Contiguity")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```
:::

# **Computing distance based neighbours**

In this section, we learn how to create distance-based weight matrices using the *dnearneigh()* function from the **spdep** package. Instead of relying on shared boundaries like Queen or Rook contiguity, this method defines neighbours based on the Euclidean distance between region centroids. We can set a minimum **d1** and maximum **d2** distance band to determine which regions are considered neighbours. If geographic coordinates are used with longlat = TRUE, the function calculates great-circle distances in kilometers with reference to WGS84.

## **Determine the cut-off distance**

Firstly, we need to determine the upper limit for distance band by using the steps below:

-   Use *knearneigh()* to find the k-nearest neighbours for each point.

-   Convert the result into a neighbour list with *knn2nb()*.

-   Measure neighbour distances with *nbdist()*, returned in coordinate units.

-   Remove the list structure of the returned object by using *unlist()*.

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report indicates that the maximum first nearest neighbour distance is 61.79 km. By setting this as the upper threshold, we can ensure that every unit will have at least one neighbour.

## **Computing fixed distance weight matrix**

We will next compute the distance weight matrix by using *dnearneigh()* as shown in the code chunk below.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Since we used 62km based on our cut off distance which we have gotten from the previous step, each region on average has about 3 to 4 neighbours.

We can use *str()* or *table()* & *card()* of **spdep** package to display the content of wm_d62 weight matrix.

::: panel-tabset
### str()

```{r}
str(wm_d62)
```

### table() and card()

```{r}
table(hunan$County, card(wm_d62))
```
:::

We will check the number of connected components in the list and show how many of such connected components are there.

```{r}
n_comp <- n.comp.nb(wm_d62)
n_comp$nc
```

This means that there is only 1 single connected component.

We can verify by checking how many regions are connected within this single connected component.

```{r}
table(n_comp$comp.id)
```

This means that all 88 regions are part of this single connected component.

### Plotting fixed distance weight matrix

Next, we will plot the distance weight matrix by using the code chunk below.

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_d62, coords, add=TRUE)
plot(k1, coords, add=TRUE, col="red", length=0.08)
```

The red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.

Alternatively, we can plot both of them next to each other by using the code chunk below.

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="1st nearest neighbours")
plot(k1, coords, add=TRUE, col="red", length=0.08)
plot(hunan$geometry, border="lightgrey", main="Distance link")
plot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)
```

## **Computing adaptive distance weight matrix**

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

```{r}
knn6 <- knn2nb(knearneigh(coords, k=6))
knn6
```

Similarly, we can display the content of the matrix by using *str()*.

```{r}
str(knn6)
```

### Plotting distance based neighbours

We can plot the weight matrix using the code chunk below.

```{r}
plot(hunan$geometry, border="lightgrey")
plot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

# **Weights based on IDW**

In this section, you will learn how to derive a spatial weight matrix based on Inversed Distance method.

In IDW, closer regions get higher weights (stronger influence) and further regions get lower weights (lower influence).This means that areas that are geographically closer are assumed to have stronger spatial relationships.

Unlike contiguity methods (Queen/Rook), which only say “neighbour or not”, IDW tells us how strong that neighbour relationship is based on distance.

First, we will compute the distances between areas by using *nbdists()* of **spdep**.

```{r}
dist <- nbdists(wm_q, coords, longlat = TRUE)
ids <- lapply(dist, function(x) 1/(x))
ids
```

# **Row-standardised Weights Matrix**

Next we now decide how to assign weights. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.

```{r}
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE)
rswm_q
```

The zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.

To see the weight of the first polygon’s eight neighbors type:

```{r}
rswm_q$weights[10]
```

Each neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.

Using the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.

```{r}
rswm_ids <- nb2listw(wm_q, glist=ids, style="B", zero.policy=TRUE)
rswm_ids
```

```{r}
summary(unlist(rswm_ids$weights))
```

# **Application of Spatial Weight Matrix**

In this section, we will learn how to create 4 different spatial lagged variables, they are:

-   spatial lag with row-standardized weights

-   spatial lag as a sum of neighbouring values

-   spatial window average

-   spatial window sum

## **Spatial lag with row-standardized weights**

We will compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.

Spatially lagged values are values that represent the **influence of neighbouring units** on each spatial unit. Instead of looking only at a polygon’s own attribute, spatial lagging takes into account the attributes of its neighbours weighted by a spatial weights matrix (such as row-standardized weights or inverse distance weights from above).

```{r}
GDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)
GDPPC.lag
```

Recalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below.

```{r}
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```

We can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.

```{r}
lag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))
lag.res <- as.data.frame(lag.list)
colnames(lag.res) <- c("NAME_3", "lag GDPPC")
hunan <- left_join(hunan,lag.res)
```

The following table shows the average neighboring income values (stored in the Inc.lag object) for each county.

```{r}
head(hunan)
```

Next, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_gdppc <- qtm(hunan, "lag GDPPC")
tmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)
```

The comparison between the raw GDPPC map and the lagged GDPPC map highlights how spatial context changes the interpretation of regional values. The raw GDPPC map shows the individual economic performance of each region, which can sometimes create sharp contrasts between neighbouring areas. In contrast, the lagged GDPPC map smooths these extremes by averaging each region’s value with those of its neighbours, reducing variance and highlighting broader spatial patterns.

## **Spatial lag as a sum of neighboring values**

We can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.

We start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.

```{r}
b_weights <- lapply(wm_q, function(x) 0*x + 1)
b_weights2 <- nb2listw(wm_q, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

With the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.

```{r}
lag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
lag.res <- as.data.frame(lag_sum)
colnames(lag.res) <- c("NAME_3", "lag_sum GDPPC")
```

First, let us examine the result by using the code chunk below.

```{r}
lag_sum
```

Next, we will append the lag_sum GDPPC field into our data frame.

```{r}
hunan <- left_join(hunan, lag.res)
```

After the append, we can proceed to plot both the GDPPC and Spatial Lag Sum GDPPC for comparison.

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_sum_gdppc <- qtm(hunan, "lag_sum GDPPC")
tmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)
```

## **Spatial window average**

The spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.

To add the diagonal element to the neighbour list, we just need to use *include.self()* from **spdep**.

```{r}
wm_qs <- include.self(wm_q)
```

Notice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909

Let us take a good look at the neighbour list of area \[1\] by using the code chunk below.

```{r}
wm_qs[[1]]
```

Notice that now \[1\] has six neighbours instead of five.

The number of neighbors increases because *include.self()* explicitly adds the region to its own neighbor list since in **spatial window average** we want to include the value of the region itself along with its neighbors.

Now we obtain weights with *nb2listw()*

```{r}
wm_qs <- nb2listw(wm_qs)
wm_qs
```

Again, we use *nb2listw()* and *glist()* to explicitly assign weight values.

Lastly, we just need to create the lag variable from our weight structure and GDPPC variable.

```{r}
lag_w_avg_gpdpc <- lag.listw(wm_qs, 
                             hunan$GDPPC)
lag_w_avg_gpdpc
```

Next, we will convert the lag variable listw object into a data frame by using *as.data.frame()*.

```{r}
lag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))
lag_wm_qs.res <- as.data.frame(lag.list.wm_qs)
colnames(lag_wm_qs.res) <- c("NAME_3", "lag_window_avg GDPPC")
```

Next, the code chunk below will be used to append *lag_window_avg GDPPC* values onto *hunan* sf data.frame by using *left_join()* of **dplyr** package.

```{r}
hunan <- left_join(hunan, lag_wm_qs.res)
```

To compare the values of lag GDPPC and Spatial window average, *kable()* of **knitr** package is used to prepare a table using the code chunk below.

```{r}
hunan %>%
  select("County", 
         "lag GDPPC", 
         "lag_window_avg GDPPC") %>%
  kable()
```

Lastly, *qtm()* of **tmap** package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.

```{r}
w_avg_gdppc <- qtm(hunan, "lag_window_avg GDPPC")
tmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)
```

## **Spatial window sum**

The **spatial window sum** is similar to the spatial window average but differs in one key way: it does not apply row-standardized weights. Instead of averaging values across neighbors (and itself), it simply sums them.

To add the diagonal element to the neighbour list, we just need to use *include.self()* from **spdep**.

```{r}
wm_qs <- include.self(wm_q)
wm_qs
```

Next, we will assign binary weights to the neighbour structure that includes the diagonal element.

```{r}
b_weights <- lapply(wm_qs, function(x) 0*x + 1)
b_weights[1]
```

The increase in neighbors here is also the same reason as the **spatial window average**.

Again, we use *nb2listw()* and *glist()* to explicitly assign weight values.

```{r}
b_weights2 <- nb2listw(wm_qs, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

With our new weight structure, we can compute the lag variable with *lag.listw()*.

```{r}
w_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
w_sum_gdppc
```

Next, we will convert the lag variable listw object into a data.frame by using *as.data.frame()*.

```{r}
w_sum_gdppc.res <- as.data.frame(w_sum_gdppc)
colnames(w_sum_gdppc.res) <- c("NAME_3", "w_sum GDPPC")
```

And append *w_sum GDPPC* values onto *hunan* sf data.frame by using *left_join()* of **dplyr** package.

```{r}
hunan <- left_join(hunan, w_sum_gdppc.res)
```

To compare the values of lag GDPPC and Spatial window sum, *kable()* of **knitr** package is used to prepare a table using the code chunk below.

```{r}
hunan %>%
  select("County", "lag_sum GDPPC", "w_sum GDPPC") %>%
  kable()
```

Lastly, *qtm()* of **tmap** package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.

```{r}
w_sum_gdppc <- qtm(hunan, "w_sum GDPPC")
tmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)
```

# **Reference**

-   [Kam, T. S. Geospatial Data Science with R. R for Geospatial Data Science and Analytics](https://r4gdsa.netlify.app/chap06#computing-stkde-by-day-of-year-improved-method)
